{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBlock(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(dim, hidden_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(hidden_dim, dim)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(self.gelu(self.linear1(x)))\n",
    "        x = self.dropout2(self.linear2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_patch, token_dim, channel_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_mix = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            Rearrange('b n d -> b d n'), #[1, 512, 196]\n",
    "            MLPBlock(num_patch, token_dim, dropout), #[1, 512 , 196]\n",
    "            Rearrange('b d n -> b n d')  #[1, 196 , 512]\n",
    "        )\n",
    "\n",
    "        self.channel_mix = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            MLPBlock(dim, channel_dim, dropout) #[1, 196, 512]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x + self.token_mix(x)\n",
    "        x = x + self.channel_mix(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPMixer(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_channels = 3, \n",
    "                 dim = 512, \n",
    "                 num_classes = 1000, \n",
    "                 patch_size = 16, \n",
    "                 image_size = 224, \n",
    "                 depth = 8, \n",
    "                 token_dim = 256, \n",
    "                 channel_dim = 2048):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        self.num_patch =  (image_size// patch_size) ** 2\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, dim, patch_size, patch_size),\n",
    "            Rearrange('b c h w -> b (h w) c'),\n",
    "        )\n",
    "        \n",
    "        self.mixer_blocks = nn.ModuleList([])\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.mixer_blocks.append(MixerBlock(dim, self.num_patch, token_dim, channel_dim))\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(dim)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### x shape: [1, 3, 224, 224]\n",
    "        x = self.to_patch_embedding(x)\n",
    "        ### x shape: [1, 196, 512]\n",
    "\n",
    "        for mixer_block in self.mixer_blocks:\n",
    "            x = mixer_block(x)\n",
    "\n",
    "        ### x shape [1, 196, 512]\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        ### x shape [1, 512]\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        return self.mlp_head(x) ### [1, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 18.528M\n",
      "Shape of out : torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "img = torch.ones([1, 3, 224, 224])\n",
    "\n",
    "model = MLPMixer(in_channels=3, image_size=224, patch_size=16, num_classes=1000, dim=512, depth=8, token_dim=256, channel_dim=2048)\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "parameters = sum([np.prod(p.size()) for p in parameters]) / 1_000_000\n",
    "print('Trainable Parameters: %.3fM' % parameters)\n",
    "\n",
    "out_img = model(img)\n",
    "print(\"Shape of out :\", out_img.shape)  # [batch_size, num_classes]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
