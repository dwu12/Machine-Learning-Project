{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "12sDvs77T_pAA_Mxd2AvsU0y_fLkthwbv",
      "authorship_tag": "ABX9TyNKasp+nOINxRS3gwfX2VEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwu12/Machine-Learning-Project/blob/main/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HPu2wVq90DK",
        "outputId": "b8ab8f73-3466-466c-8179-4d37fded29d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install torchmetrics\n",
        "\n",
        "from torchmetrics.functional import bleu_score\n",
        "from torchtext.data.metrics import bleu_score as bs\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and DataLoader"
      ],
      "metadata": {
        "id": "7c2RZj13-lwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://github.com/desmondyeoh/data-eng-fra/blob/master/eng-fra.txt'\n",
        "\n",
        "def read_data_nmt():\n",
        "    \"\"\"载入“英语－法语”数据集\"\"\"\n",
        "    with open('/content/drive/MyDrive/DL/RNN/eng-fra.txt', 'r',\n",
        "             encoding='utf-8') as f:\n",
        "        return f.read()\n",
        "\n",
        "raw_text = read_data_nmt()\n",
        "print(raw_text[:75])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOb0X2Zi94F6",
        "outputId": "90783125-6577-47c6-fdc2-48fe17a96b9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tVa !\n",
            "Run!\tCours !\n",
            "Run!\tCourez !\n",
            "Wow!\tÇa alors !\n",
            "Fire!\tAu feu !\n",
            "Help!\tÀ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_nmt(text):\n",
        "    \"\"\"预处理“英语－法语”数据集\"\"\"\n",
        "    def no_space(char, prev_char):\n",
        "        return char in set(',.!?') and prev_char != ' '\n",
        "\n",
        "    # 使用空格替换不间断空格\n",
        "    # 使用小写字母替换大写字母\n",
        "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
        "    # 在单词和标点符号之间插入空格\n",
        "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text)]\n",
        "    return ''.join(out)\n",
        "\n",
        "text = preprocess_nmt(raw_text)\n",
        "print(text[:80])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr9pOkW--qq0",
        "outputId": "b5c0723c-79ce-4674-986a-69b3988cbe9e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go .\tva !\n",
            "run !\tcours !\n",
            "run !\tcourez !\n",
            "wow !\tça alors !\n",
            "fire !\tau feu !\n",
            "help !\tà\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_nmt(text, num_examples=None):\n",
        "    \"\"\"词元化“英语－法语”数据数据集\"\"\"\n",
        "    source, target = [], []\n",
        "    for i, line in enumerate(text.split('\\n')):\n",
        "        if num_examples and i > num_examples:\n",
        "            break\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) == 2:\n",
        "            source.append(parts[0].split(' '))\n",
        "            target.append(parts[1].split(' '))\n",
        "    return source, target\n",
        "\n",
        "source, target = tokenize_nmt(text)\n",
        "source[:6], target[:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o-WdzOQ-xuM",
        "outputId": "42615cfe-9dec-42c3-d253-9d6032e6915f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['go', '.'],\n",
              "  ['run', '!'],\n",
              "  ['run', '!'],\n",
              "  ['wow', '!'],\n",
              "  ['fire', '!'],\n",
              "  ['help', '!']],\n",
              " [['va', '!'],\n",
              "  ['cours', '!'],\n",
              "  ['courez', '!'],\n",
              "  ['ça', 'alors', '!'],\n",
              "  ['au', 'feu', '!'],\n",
              "  ['à', \"l'aide\", '!']])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n",
        "        if tokens is None:\n",
        "            tokens = []\n",
        "        if reserved_tokens is None:\n",
        "            reserved_tokens = []\n",
        "\n",
        "        counter = self.count_corpus(tokens)\n",
        "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        self.idx_to_token = ['<unk>'] + reserved_tokens\n",
        "        self.token_to_idx = {token: idx\n",
        "                             for idx, token in enumerate(self.idx_to_token)}\n",
        "        for token, freq in self._token_freqs:\n",
        "            if freq < min_freq:\n",
        "                break\n",
        "            if token not in self.token_to_idx:\n",
        "                self.idx_to_token.append(token)\n",
        "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "\n",
        "    def count_corpus(self, tokens):\n",
        "        if len(tokens) == 0 or isinstance(tokens[0], list):\n",
        "          tokens = [token for line in tokens for token in line]\n",
        "        return collections.Counter(tokens)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        if not isinstance(tokens, (list, tuple)):\n",
        "            return self.token_to_idx.get(tokens, self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        if not isinstance(indices, (list, tuple)):\n",
        "            return self.idx_to_token[indices]\n",
        "        return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "    @property\n",
        "    def unk(self):  # 未知词元的索引为0\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def token_freqs(self):\n",
        "        return self._token_freqs"
      ],
      "metadata": {
        "id": "gMjpXPZd-zZl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab = Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "len(src_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxgjQj_R-1Vz",
        "outputId": "bba14f43-c97b-48cb-de95-896d3075a29a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9339"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_pad(line, num_steps, padding_token):\n",
        "    \"\"\"截断或填充文本序列\"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps]  # 截断\n",
        "    return line + [padding_token] * (num_steps - len(line))  # 填充\n",
        "\n",
        "truncate_pad(src_vocab[source[0]], 10, src_vocab['<pad>'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj-yHyUO-25t",
        "outputId": "8b0686d1-b4dc-4e0f-daea-14ccd7e3eb59"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[48, 4, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_array_nmt(lines, vocab, num_steps):\n",
        "    \"\"\"将机器翻译的文本序列转换成小批量\"\"\"\n",
        "    lines = [vocab[l] for l in lines]\n",
        "    lines = [l + [vocab['<eos>']] for l in lines]\n",
        "    array = torch.tensor([truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
        "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
        "    return array, valid_len"
      ],
      "metadata": {
        "id": "olrhcjzF-4XL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class customer_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        super(customer_dataset, self).__init__()\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample, label = self.features[idx,:], self.labels[idx,:]\n",
        "        return sample, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)"
      ],
      "metadata": {
        "id": "61mtv-UW-6BE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
        "    \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n",
        "    text = preprocess_nmt(read_data_nmt())\n",
        "    source, target = tokenize_nmt(text, num_examples)\n",
        "\n",
        "    ## Get source vocab and target vocab\n",
        "    src_vocab = Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "    tgt_vocab = Vocab(target, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
        "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
        "\n",
        "    ### get data\n",
        "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
        "    dataset = customer_dataset(src_array, tgt_array)\n",
        "    data_iter = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle=True)\n",
        "    return data_iter, src_vocab, tgt_vocab"
      ],
      "metadata": {
        "id": "I3iObv1S-8V0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n",
        "                  cmap='Reds'):\n",
        "    \"\"\"显示矩阵热图\"\"\"\n",
        "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize,\n",
        "                                 sharex=True, sharey=True, squeeze=False)\n",
        "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
        "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
        "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
        "            if i == num_rows - 1:\n",
        "                ax.set_xlabel(xlabel)\n",
        "            if j == 0:\n",
        "                ax.set_ylabel(ylabel)\n",
        "            if titles:\n",
        "                ax.set_title(titles[j])\n",
        "    fig.colorbar(pcm, ax=axes, shrink=0.6)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bFmOgR3w--Ch"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "HSuYK-pv_D2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
        "    \"\"\"训练序列到序列模型\"\"\"\n",
        "    def xavier_init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "        if type(m) == nn.GRU:\n",
        "            for param in m._flat_weights_names:\n",
        "                if \"weight\" in param:\n",
        "                    nn.init.xavier_uniform_(m._parameters[param])\n",
        "\n",
        "    net.apply(xavier_init_weights)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    loss = nn.CrossEntropyLoss(ignore_index= 1)\n",
        "    net.train()\n",
        "\n",
        "    metric = []\n",
        "    for epoch in range(num_epochs):\n",
        "        for X, Y in data_iter:\n",
        "            optimizer.zero_grad()\n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0], device=device).reshape(-1, 1)\n",
        "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # 强制教学\n",
        "            Y_hat = net(X, dec_input)\n",
        "            l = loss(Y_hat.reshape(-1, Y_hat.shape[2]), Y.reshape(-1))\n",
        "            l.backward()\n",
        "            clip_grad_norm_(net.parameters(), 1)\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                metric.append(l)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'loss {sum(metric)/len(metric)}')"
      ],
      "metadata": {
        "id": "kFRsfwwH-_K9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "lqdVNpQ0_We3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        # Initialize dimensions\n",
        "        self.d_model = d_model # Model's dimension\n",
        "        self.num_heads = num_heads # Number of attention heads\n",
        "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
        "\n",
        "        # Linear layers for transforming inputs\n",
        "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
        "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
        "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
        "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        # Calculate attention scores\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Softmax is applied to obtain attention probabilities\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # Multiply by values to obtain the final output\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        # Reshape the input to have num_heads for multi-head attention\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        # Combine the multiple heads back to original shape\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        # Apply linear transformations and split heads\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        # Perform scaled dot-product attention\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "\n",
        "        # Combine heads and apply output transformation\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output"
      ],
      "metadata": {
        "id": "_S8spe38_IpZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))"
      ],
      "metadata": {
        "id": "5U7iN7sb_mqi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ],
      "metadata": {
        "id": "md1aodNh_aUs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "uxdZcuaB_fSj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "n_o-Q20b_tps"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, d_model, num_heads, d_ff, dropout, src_vocab_size, num_layers, max_seq_length):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "    self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "    self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.d_model = d_model\n",
        "\n",
        "  def forward(self, src, src_mask):\n",
        "    src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src) * math.sqrt(self.d_model)))\n",
        "    enc_output = src_embedded\n",
        "    for enc_layer in self.encoder_layers:\n",
        "        enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "    return enc_output\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, d_model, num_heads, d_ff, dropout, tgt_vocab_size, num_layers, max_seq_length):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "    self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "    self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "    self.d_model = d_model\n",
        "\n",
        "  def forward(self, tgt, enc_output, src_mask, tgt_mask):\n",
        "    tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt) * math.sqrt(self.d_model)))\n",
        "\n",
        "    dec_output = tgt_embedded\n",
        "    for dec_layer in self.decoder_layers:\n",
        "        dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "    output = self.fc(dec_output)\n",
        "    return output\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(d_model, num_heads, d_ff, dropout, src_vocab_size, num_layers, max_seq_length)\n",
        "        self.decoder = Decoder(d_model, num_heads, d_ff, dropout, tgt_vocab_size, num_layers, max_seq_length)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 1).unsqueeze(1).unsqueeze(2).to('cuda')\n",
        "        tgt_mask = (tgt != 1).unsqueeze(1).unsqueeze(3).to('cuda')\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to('cuda')\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "\n",
        "        enc_output = self.encoder(src, src_mask)\n",
        "        dec_output = self.decoder(tgt, enc_output, src_mask, tgt_mask)\n",
        "        return dec_output"
      ],
      "metadata": {
        "id": "fjAonYfsa4P8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###training details"
      ],
      "metadata": {
        "id": "j6k2ReUzBarM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "train_iter, src_vocab, tgt_vocab = load_data_nmt(32, 10)"
      ],
      "metadata": {
        "id": "DTuIye1ABdI0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_vocab_size = len(src_vocab)\n",
        "tgt_vocab_size = len(tgt_vocab)\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "num_layers = 2\n",
        "d_ff = 128\n",
        "max_seq_length = 10\n",
        "dropout = 0.1\n",
        "lr, num_epochs = 0.005, 500\n",
        "model = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)"
      ],
      "metadata": {
        "id": "eHUHvhlkB1Dr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq2seq(model, train_iter, lr, num_epochs, tgt_vocab, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HOCQpPGDFRn",
        "outputId": "87b80fc5-02e0-4a01-f0ad-40463d658db1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 2.0735135078430176\n",
            "loss 1.6619459390640259\n",
            "loss 1.4155644178390503\n",
            "loss 1.2492358684539795\n",
            "loss 1.1273351907730103\n",
            "loss 1.0305633544921875\n",
            "loss 0.9532252550125122\n",
            "loss 0.8911542892456055\n",
            "loss 0.8382785320281982\n",
            "loss 0.7935157418251038\n",
            "loss 0.7558156847953796\n",
            "loss 0.7227541208267212\n",
            "loss 0.6941323280334473\n",
            "loss 0.6693258285522461\n",
            "loss 0.647087037563324\n",
            "loss 0.6265802383422852\n",
            "loss 0.6077691316604614\n",
            "loss 0.5912443399429321\n",
            "loss 0.576025664806366\n",
            "loss 0.5620740056037903\n",
            "loss 0.5493149757385254\n",
            "loss 0.5376784205436707\n",
            "loss 0.526922881603241\n",
            "loss 0.5169119834899902\n",
            "loss 0.5075514316558838\n",
            "loss 0.49884966015815735\n",
            "loss 0.4906163513660431\n",
            "loss 0.4826175570487976\n",
            "loss 0.4753783345222473\n",
            "loss 0.4689069986343384\n",
            "loss 0.4626474380493164\n",
            "loss 0.456558495759964\n",
            "loss 0.4507838189601898\n",
            "loss 0.44537872076034546\n",
            "loss 0.44019585847854614\n",
            "loss 0.4351275563240051\n",
            "loss 0.4304210841655731\n",
            "loss 0.42597100138664246\n",
            "loss 0.4216630160808563\n",
            "loss 0.4176138639450073\n",
            "loss 0.41363176703453064\n",
            "loss 0.4098060727119446\n",
            "loss 0.4063208997249603\n",
            "loss 0.4027956426143646\n",
            "loss 0.3995220363140106\n",
            "loss 0.39645108580589294\n",
            "loss 0.3934294283390045\n",
            "loss 0.39036452770233154\n",
            "loss 0.3874494731426239\n",
            "loss 0.38477349281311035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "V0mB3CVgEcP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
        "                    device, save_attention_weights=False):\n",
        "    \"\"\"序列到序列模型的预测\"\"\"\n",
        "    # 在预测时将net设置为评估模式\n",
        "    net.eval()\n",
        "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [src_vocab['<eos>']]\n",
        "    #print('what is src_tokens', src_tokens)\n",
        "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
        "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
        "    #print('what is src_tokens', src_tokens)\n",
        "    # 添加批量轴\n",
        "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
        "    src_mask = (enc_X != 1).unsqueeze(1).unsqueeze(2).to('cuda')\n",
        "    #print('what is encoder x', enc_X.shape)\n",
        "    enc_outputs = net.encoder(enc_X, src_mask)\n",
        "    # dec_state = net.decoder.init_state(enc_outputs, None)\n",
        "    # 添加批量轴\n",
        "    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
        "    #print('what is decoder x', dec_X.shape)\n",
        "    output_seq, attention_weight_seq = [], []\n",
        "    for _ in range(num_steps):\n",
        "        Y = net.decoder(dec_X, enc_outputs, src_mask, None)\n",
        "        #print(Y.shape)\n",
        "        #print(dec_state.shape)\n",
        "        # 我们使用具有预测最高可能性的词元，作为解码器在下一时间步的输入\n",
        "        dec_X = Y.argmax(dim=2)\n",
        "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
        "        # 保存注意力权重（稍后讨论）\n",
        "        # if save_attention_weights:\n",
        "        #     attention_weight_seq.append(net.decoder.attention_weights)\n",
        "        # 一旦序列结束词元被预测，输出序列的生成就完成了\n",
        "        if pred == tgt_vocab['<eos>']:\n",
        "            break\n",
        "        output_seq.append(pred)\n",
        "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
      ],
      "metadata": {
        "id": "gvK5ddNVEL_F"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
        "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
        "for eng, fra in zip(engs, fras):\n",
        "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
        "        model, eng, src_vocab, tgt_vocab, 10, device, False)\n",
        "    print(f'{eng} => {translation}, bleu { bleu_score([translation], [fra], n_gram=2) :.3f}')\n",
        "    A = bs( candidate_corpus = [translation.split(' ')], references_corpus= [[fra.split(' ')]], max_n=2, weights = [0.5, 0.5])\n",
        "    print(f'{eng} => {translation}, bleu { A:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUu9vDTZHGe8",
        "outputId": "167c8f9b-5846-4585-aca9-303dca6b44ec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go . => va !, bleu 1.000\n",
            "go . => va !, bleu 1.000\n",
            "i lost . => j'ai perdu ., bleu 1.000\n",
            "i lost . => j'ai perdu ., bleu 1.000\n",
            "he's calm . => il ., bleu 0.000\n",
            "he's calm . => il ., bleu 0.000\n",
            "i'm home . => je suis ., bleu 0.363\n",
            "i'm home . => je suis ., bleu 0.363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `bleu_score` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `bleu_score` from `torchmetrics.text` instead.\n",
            "  _future_warning(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJ0q_l3WHI9S"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}