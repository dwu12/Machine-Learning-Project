{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from lxml import etree\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umeng Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_window():\n",
    "    '''\n",
    "    打开一个chrome窗口，停用开发者模式\n",
    "    实例化浏览器对象\n",
    "    return 一个driver对象\n",
    "    '''\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "    # 设置浏览器初始 位置x,y & 宽高x,y\n",
    "    chrome_options.add_argument(f'--window-position={217},{172}')\n",
    "    chrome_options.add_argument(f'--window-size={1200},{1000}')\n",
    "\n",
    "    # 关闭自动测试状态显示 // 会导致浏览器报：请停用开发者模式\n",
    "    # window.navigator.webdriver还是返回True,当返回undefined时应该才可行。\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", ['enable-automation'])\n",
    "    prefs = {\n",
    "            'profile.default_content_setting_values':\n",
    "                {\n",
    "                    'notifications': 2\n",
    "                }\n",
    "        }\n",
    "    chrome_options.add_experimental_option('prefs', prefs)\n",
    "    chrome_options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "    #chrome_options.add_argument('--headless') \n",
    "    #隐藏浏览器\n",
    "    # 部署项目在linux时，其驱动会要求这个参数\n",
    "    #chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument(\n",
    "            'user-agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36\"')\n",
    "    #实例化浏览器对象\n",
    "    driver = webdriver.Chrome(executable_path = './chromedriver', options = chrome_options)\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "            \"source\": \"\"\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\"\"\",\n",
    "        })\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cookie_dic(s):\n",
    "    '''\n",
    "    将cookie元数据输入，返还一个cookie的dictionary，用于登陆网站以及post/get命令请求\n",
    "    '''\n",
    "    dic_c = {}\n",
    "    for x in s.split('; '):\n",
    "        dic_c[x.split(\"=\")[0]] = x.split(\"=\")[1]\n",
    "    return dic_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_trend(driver, dic_c , date_begin, date_end, platform):\n",
    "    '''\n",
    "    get total trend information from Umeng and export data into total_trend.csv\n",
    "    '''\n",
    "    driver.get(\"https://mobile.umeng.com/platform/{}/reports/trend_summary\".format(platform))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for i in dic_c:\n",
    "        driver.add_cookie({'name':i,'value': dic_c[i]})\n",
    "    driver.refresh()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    date1 = driver.find_elements_by_class_name(\"ant-calendar-range-picker-input\")\n",
    "    date1[0].click()\n",
    "\n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_begin[0])\n",
    "    time.sleep(2)\n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[1].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[1].send_keys(date_end[1])\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    \n",
    "    button = driver.find_element_by_xpath('//*[@id=\"scroll-container\"]/div/div[2]/div/div/div[3]/div[4]/div[1]/div[1]/span/div[2]/a/span')\n",
    "    button.click()\n",
    "\n",
    "    time.sleep(2)\n",
    "    \n",
    "    head_list = driver.find_elements_by_class_name(\"ant-table-column-title\")\n",
    "    header_list = [i.text for i in head_list]\n",
    "    total_trend = pd.DataFrame( columns= header_list)\n",
    "    time.sleep(5)\n",
    "    data_list = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    for i in data_list:\n",
    "        total_trend.loc[len(total_trend)] = i.text.split(\" \")\n",
    "    \n",
    "    total_trend.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\total_trend.csv\",encoding = \"utf-8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_stay(driver, dic_c, date_begin, date_end, platform):\n",
    "    '''\n",
    "    return 两周的新用户存留表到new_user_stay.csv, 活跃用户留存表到active_user_stay.csv\n",
    "    '''\n",
    "    driver.get(\"https://mobile.umeng.com/platform/{}/reports/retention\".format(platform))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print(\"am i here?\")\n",
    "    for i in dic_c:\n",
    "        driver.add_cookie({'name':i,'value': dic_c[i]})\n",
    "    driver.refresh()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    print(\"am i here????\")\n",
    "    button = driver.find_element_by_xpath('//*[@id=\"scroll-container\"]/div/div[2]/div/div[2]/div[1]/div[1]/div[1]/span/div[1]/div/label[1]/span[2]/span')\n",
    "    button.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    date1 = driver.find_elements_by_class_name(\"ant-calendar-range-picker-input\")\n",
    "    date1[0].click()\n",
    "\n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_begin[0])\n",
    "    time.sleep(2)\n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[1].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[1].send_keys(date_end[1])\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    \n",
    "    head_list = driver.find_elements_by_class_name(\"ant-table-column-title\")\n",
    "    count = len(head_list)\n",
    "    header_list = [i.text for i in head_list]\n",
    "    #print(header_list)\n",
    "\n",
    "    new_user_stay = pd.DataFrame( columns= header_list)\n",
    "    time.sleep(5)\n",
    "    data_list = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    for i in data_list:\n",
    "        l  = i.text.split(\"\\n\")\n",
    "        if len(l) < count:\n",
    "            for j in range(count-len(l)):\n",
    "                l.append(\"\")\n",
    "        new_user_stay.loc[len(new_user_stay)] = l\n",
    "        \n",
    "    new_user_stay.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\new_user_stay.csv\",encoding = \"utf-8_sig\")\n",
    "    \n",
    "    #活跃用户\n",
    "    button = driver.find_element_by_xpath('//*[@id=\"scroll-container\"]/div/div[2]/div/div[2]/div[1]/div[1]/div[1]/span/div[1]/div/label[2]/span[2]/span')\n",
    "    button.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    head_list = driver.find_elements_by_class_name(\"ant-table-column-title\")\n",
    "    count = len(head_list)\n",
    "    header_list = [i.text for i in head_list]\n",
    "    #print(header_list)\n",
    "\n",
    "    active_user_stay = pd.DataFrame( columns= header_list)\n",
    "    time.sleep(5)\n",
    "    data_list = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    for i in data_list:\n",
    "        l  = i.text.split(\"\\n\")\n",
    "        if len(l) < count:\n",
    "            for j in range(count-len(l)):\n",
    "                l.append(\"\")\n",
    "        active_user_stay.loc[len(active_user_stay)] = l\n",
    "        \n",
    "    active_user_stay.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\active_user_stay.csv\",encoding = \"utf-8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comma_out(x):\n",
    "    if ',' in str(x):\n",
    "        return str(x).replace(',','')\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(driver, dic_c, date_begin, date_end, platform):\n",
    "    '''\n",
    "    return 两周的设备终端信息到 device.csv\n",
    "    '''\n",
    "    driver.get(\"https://mobile.umeng.com/platform/{}/reports/device\".format(platform))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for i in dic_c:\n",
    "        driver.add_cookie({'name':i,'value': dic_c[i]})\n",
    "    driver.refresh()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    date = driver.find_element_by_class_name(\"ant-calendar-picker-icon\")\n",
    "    date.click()\n",
    "    \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_begin[1])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    head = driver.find_elements_by_class_name(\"ant-table-column-title\")[4:]\n",
    "    header_list = [i.text for i in head]\n",
    "    device1 = pd.DataFrame( columns= header_list)\n",
    "    \n",
    "    \n",
    "    while driver.find_element_by_class_name(\"ant-pagination-next\").get_attribute(\"aria-disabled\") == 'false':\n",
    "        data = driver.find_elements_by_class_name(\"ant-table-row\")[4:]\n",
    "        time.sleep(1)\n",
    "        for i in data:\n",
    "            l = i.text.split(' ')\n",
    "            if len(l) > len(header_list):\n",
    "                result = []\n",
    "                phone = ' '.join(l[:len(l)-len(header_list)+1])\n",
    "                result.append(phone)\n",
    "                result.extend(l[len(l)-len(header_list)+1:])\n",
    "                device1.loc[len(device1)] = result\n",
    "            else:\n",
    "                device1.loc[len(device1)] = l\n",
    "        driver.find_element_by_class_name(\"ant-pagination-next\").click()\n",
    "        time.sleep(1)\n",
    "    \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")[4:]\n",
    "    for i in data:\n",
    "        l = i.text.split(' ')\n",
    "        if len(l) > len(header_list):\n",
    "            result = []\n",
    "            phone = ' '.join(l[:len(l)-len(header_list)+1])\n",
    "            result.append(phone)\n",
    "            result.extend(l[len(l)-len(header_list)+1:])\n",
    "            device1.loc[len(device1)] = result\n",
    "        else:\n",
    "            device1.loc[len(device1)] = l\n",
    "    \n",
    "    #switch date\n",
    "    date = driver.find_element_by_class_name(\"ant-calendar-picker-icon\")\n",
    "    date.click()\n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_end[1])\n",
    "    time.sleep(1)\n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    device2 = pd.DataFrame( columns= header_list)\n",
    "    \n",
    "    \n",
    "    while driver.find_element_by_class_name(\"ant-pagination-next\").get_attribute(\"aria-disabled\") == 'false':\n",
    "        data = driver.find_elements_by_class_name(\"ant-table-row\")[4:]\n",
    "        time.sleep(1)\n",
    "        for i in data:\n",
    "            l = i.text.split(' ')\n",
    "            if len(l) > len(header_list):\n",
    "                result = []\n",
    "                phone = ' '.join(l[:len(l)-len(header_list)+1])\n",
    "                result.append(phone)\n",
    "                result.extend(l[len(l)-len(header_list)+1:])\n",
    "                device2.loc[len(device2)] = result\n",
    "            else:\n",
    "                device2.loc[len(device2)] = l\n",
    "\n",
    "        driver.find_element_by_class_name(\"ant-pagination-next\").click()\n",
    "        time.sleep(1)\n",
    "        \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")[4:]\n",
    "    for i in data:\n",
    "        l = i.text.split(' ')\n",
    "        if len(l) > len(header_list):\n",
    "            result = []\n",
    "            phone = ' '.join(l[:len(l)-len(header_list)+1])\n",
    "            result.append(phone)\n",
    "            result.extend(l[len(l)-len(header_list)+1:])\n",
    "            device2.loc[len(device1)] = result\n",
    "        else:\n",
    "            device2.loc[len(device1)] = l\n",
    "            \n",
    "    device1 = device1[['机型','新增用户','启动次数']]\n",
    "    device2 = device2[['机型','新增用户','启动次数']]\n",
    "    device =  pd.merge(device1, device2, on='机型',how = 'outer')\n",
    "    \n",
    "    device = device.fillna(0)\n",
    "    device['启动次数_x'] = device['启动次数_x'].apply(get_comma_out)\n",
    "    device['启动次数_y'] = device['启动次数_y'].apply(get_comma_out)\n",
    "    device['新增用户_x'] = device['新增用户_x'].apply(get_comma_out)\n",
    "    device['新增用户_y'] = device['新增用户_y'].apply(get_comma_out)\n",
    "    \n",
    "    device['新增用户_x'] = device['新增用户_x'].astype(int)\n",
    "    device['新增用户_y'] = device['新增用户_y'].astype(int)\n",
    "    device['启动次数_x'] = device['启动次数_x'].astype(int)\n",
    "    device['启动次数_y'] = device['启动次数_y'].astype(int)\n",
    "\n",
    "    device['新增用户'] = device[\"新增用户_x\"]+device[\"新增用户_y\"]\n",
    "    device['启动次数'] = device[\"启动次数_x\"]+device[\"启动次数_y\"]\n",
    "    device = device[['机型','新增用户','启动次数']]\n",
    "    \n",
    "    device.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\device.csv\",encoding = \"utf-8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(driver, dic_c, date_begin, date_end, platform):\n",
    "    '''\n",
    "    return location information into province.csv and country.csv\n",
    "    '''\n",
    "    driver.get(\"https://mobile.umeng.com/platform/{}/reports/location\".format(platform))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for i in dic_c:\n",
    "        driver.add_cookie({'name':i,'value': dic_c[i]})\n",
    "    driver.refresh()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    button = driver.find_element_by_xpath('//*[@id=\"scroll-container\"]/div/div[2]/div/div[1]/div[2]/div[1]/div/label[1]/span[2]/span')\n",
    "    button.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    date = driver.find_element_by_class_name(\"ant-calendar-picker-icon\")\n",
    "    date.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_begin[1])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    head = driver.find_elements_by_class_name(\"ant-table-column-title\")\n",
    "    header_list = [i.text for i in head]\n",
    "    header_list\n",
    "    \n",
    "    province = pd.DataFrame( columns= header_list)\n",
    "    \n",
    "    \n",
    "  \n",
    "    while driver.find_element_by_class_name(\"ant-pagination-next\").get_attribute(\"aria-disabled\") == 'false':\n",
    "        data = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "        time.sleep(1)\n",
    "        for i in data:\n",
    "            l = i.text.split(' ')\n",
    "            province.loc[len(province)] = l\n",
    "\n",
    "        driver.find_element_by_class_name(\"ant-pagination-next\").click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    time.sleep(1)\n",
    "    for i in data:\n",
    "        l = i.text.split(' ')\n",
    "        province.loc[len(province)] = l\n",
    "\n",
    "    #switch \n",
    "\n",
    "    date = driver.find_element_by_class_name(\"ant-calendar-picker-icon\")\n",
    "    date.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_end[1])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    \n",
    "    province2 = pd.DataFrame( columns= header_list)\n",
    "    \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    while driver.find_element_by_class_name(\"ant-pagination-next\").get_attribute(\"aria-disabled\") == 'false':\n",
    "        for i in data:\n",
    "            l = i.text.split(' ')\n",
    "            province2.loc[len(province2)] = l\n",
    "\n",
    "        driver.find_element_by_class_name(\"ant-pagination-next\").click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    for i in data:\n",
    "        l = i.text.split(' ')\n",
    "        province2.loc[len(province2)] = l\n",
    "    \n",
    "    province = province[['省市','新增用户','活跃用户','启动次数']]\n",
    "    province2 = province2[['省市','新增用户','活跃用户','启动次数']]\n",
    "    province =  pd.merge(province, province2, on='省市',how = 'outer')\n",
    "    province = province.fillna(0)\n",
    "    \n",
    "    province['启动次数_x'] = province['启动次数_x'].apply(get_comma_out)\n",
    "    province['启动次数_y'] = province['启动次数_y'].apply(get_comma_out)\n",
    "    province['新增用户_x'] = province['新增用户_x'].apply(get_comma_out)\n",
    "    province['新增用户_y'] = province['新增用户_y'].apply(get_comma_out)\n",
    "    province['活跃用户_x'] = province['活跃用户_x'].apply(get_comma_out)\n",
    "    province['活跃用户_y'] = province['活跃用户_y'].apply(get_comma_out)\n",
    "    \n",
    "    province['新增用户_x'] = province['新增用户_x'].astype(int)\n",
    "    province['新增用户_y'] = province['新增用户_y'].astype(int)\n",
    "    province['启动次数_x'] = province['启动次数_x'].astype(int)\n",
    "    province['启动次数_y'] = province['启动次数_y'].astype(int)\n",
    "    province['活跃用户_x'] = province['活跃用户_x'].astype(int)\n",
    "    province['活跃用户_y'] = province['活跃用户_y'].astype(int)\n",
    "\n",
    "    province['新增用户'] = province[\"新增用户_x\"]+province[\"新增用户_y\"]\n",
    "    province['活跃用户'] = province[\"活跃用户_x\"]+province[\"活跃用户_y\"]\n",
    "    province['启动次数'] = province[\"启动次数_x\"]+province[\"启动次数_y\"]\n",
    "    \n",
    "    province = province[['省市','新增用户','活跃用户','启动次数']]\n",
    "    \n",
    "    province.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\province.csv\",encoding = \"utf-8_sig\")\n",
    "    \n",
    "    #switch to country\n",
    "    button = driver.find_element_by_xpath('//*[@id=\"scroll-container\"]/div/div[2]/div/div[1]/div[2]/div[1]/div/label[2]/span[2]/span')\n",
    "    button.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    date = driver.find_element_by_class_name(\"ant-calendar-picker-icon\")\n",
    "    date.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_begin[1])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    head = driver.find_elements_by_class_name(\"ant-table-column-title\")\n",
    "    header_list = [i.text for i in head]\n",
    "    header_list\n",
    "    \n",
    "    country = pd.DataFrame( columns= header_list)\n",
    "    \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    time.sleep(1)\n",
    "    while driver.find_element_by_class_name(\"ant-pagination-next\").get_attribute(\"aria-disabled\") == 'false':\n",
    "        for i in data:\n",
    "            l = i.text.split(' ')\n",
    "            country.loc[len(country)] = l\n",
    "\n",
    "        driver.find_element_by_class_name(\"ant-pagination-next\").click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    time.sleep(1)\n",
    "    for i in data:\n",
    "        l = i.text.split(' ')\n",
    "        country.loc[len(country)] = l\n",
    "        \n",
    "    # switch to date\n",
    "    \n",
    "    date = driver.find_element_by_class_name(\"ant-calendar-picker-icon\")\n",
    "    date.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_end[1])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    country2 = pd.DataFrame( columns= header_list)\n",
    "    \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    time.sleep(1)\n",
    "    while driver.find_element_by_class_name(\"ant-pagination-next\").get_attribute(\"aria-disabled\") == 'false':\n",
    "        for i in data:\n",
    "            l = i.text.split(' ')\n",
    "            country2.loc[len(country2)] = l\n",
    "\n",
    "        driver.find_element_by_class_name(\"ant-pagination-next\").click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    time.sleep(1)\n",
    "    for i in data:\n",
    "        l = i.text.split(' ')\n",
    "        country2.loc[len(country2)] = l\n",
    "        \n",
    "    country = country[['国家/地区','新增用户','活跃用户','启动次数']]\n",
    "    country2 = country2[['国家/地区','新增用户','活跃用户','启动次数']]\n",
    "    country =  pd.merge(country, country2, on='国家/地区',how = 'outer')\n",
    "    country = country.fillna(0)\n",
    "    \n",
    "    country['启动次数_x'] = country['启动次数_x'].apply(get_comma_out)\n",
    "    country['启动次数_y'] = country['启动次数_y'].apply(get_comma_out)\n",
    "    country['新增用户_x'] = country['新增用户_x'].apply(get_comma_out)\n",
    "    country['新增用户_y'] = country['新增用户_y'].apply(get_comma_out)\n",
    "    country['活跃用户_x'] = country['活跃用户_x'].apply(get_comma_out)\n",
    "    country['活跃用户_y'] = country['活跃用户_y'].apply(get_comma_out)\n",
    "    \n",
    "    country['新增用户_x'] = country['新增用户_x'].astype(int)\n",
    "    country['新增用户_y'] = country['新增用户_y'].astype(int)\n",
    "    country['启动次数_x'] = country['启动次数_x'].astype(int)\n",
    "    country['启动次数_y'] = country['启动次数_y'].astype(int)\n",
    "    country['活跃用户_x'] = country['活跃用户_x'].astype(int)\n",
    "    country['活跃用户_y'] = country['活跃用户_y'].astype(int)\n",
    "\n",
    "    country['新增用户'] = country[\"新增用户_x\"]+country[\"新增用户_y\"]\n",
    "    country['活跃用户'] = country[\"活跃用户_x\"]+country[\"活跃用户_y\"]\n",
    "    country['启动次数'] = country[\"启动次数_x\"]+country[\"启动次数_y\"]\n",
    "\n",
    "    country = country[['国家/地区','新增用户','活跃用户','启动次数']]\n",
    "    \n",
    "    country.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\country.csv\",encoding = \"utf-8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_active_user_time(driver, dic_c, date_begin, platform):\n",
    "    '''\n",
    "    get active user time in 24 hours for 2 weeks\n",
    "    '''\n",
    "    driver.get(\"https://mobile.umeng.com/platform/{}/reports/active_user\".format(platform))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for i in dic_c:\n",
    "        driver.add_cookie({'name':i,'value': dic_c[i]})\n",
    "    driver.refresh()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    date1 = driver.find_elements_by_class_name(\"ant-calendar-range-picker-input\")\n",
    "    date1[0].click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_begin[1])\n",
    "\n",
    "    time.sleep(1)\n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[1].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[1].send_keys(date_begin[1])\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    date1 = driver.find_elements_by_class_name(\"ant-calendar-range-picker-input\")\n",
    "    date1[0].click()\n",
    "\n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date_begin[0])\n",
    "    time.sleep(1)\n",
    "\n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[1].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[1].send_keys(date_begin[1])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    button = driver.find_element_by_xpath('//*[@id=\"scroll-container\"]/div/div[2]/div/div[2]/div[1]/div[1]/span/div[2]/div/label[5]/span[2]/span')\n",
    "    button.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    url = \"https://mobile.umeng.com/ht/api/v3/app/user/active/trend?relatedId={}&dataSourceId={}\".format(platform,platform)\n",
    "    \n",
    "    data = {\"fromDate\":date_begin[0],\"toDate\":date_begin[1],\"version\":[],\"channel\":[],\"timeUnit\":\"hour\",\"view\":\"activeUser\",\"relatedId\":\"{}\".format(platform),\"dataSourceId\":\"{}\".format(platform)}\n",
    "    \n",
    "    headers = {\n",
    "        'accept':\"application/json, text/plain, */*\",\n",
    "        \"accept-encoding\":\"gzip, deflate, br\",\n",
    "        \"accept-language\":\"zh-CN,zh;q=0.9\",\n",
    "        \"content-length\": \"192\",\n",
    "        \"content-type\":\"application/json;charset=UTF-8\",\n",
    "        \"origin\":\"https://mobile.umeng.com\",\n",
    "        \"referer\": \"https://mobile.umeng.com/platform/{}/reports/active_user\".format(platform),\n",
    "        \"sec-fetch-dest\": \"empty\",\n",
    "        \"sec-fetch-mode\" : \"cors\",\n",
    "        \"sec-fetch-site\": \"same-origin\",\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36\",\n",
    "        \"x-xsrf-token\":\"180ef43b-dc03-4746-9e15-b7d856a07d27\",\n",
    "        \"x-xsrf-token-haitang\": \"9286eca8-5ecc-4e77-b073-6bc66f958692\"\n",
    "    }\n",
    "    \n",
    "    response =requests.post(url = url,\n",
    "        json=data,\n",
    "        cookies=dic_c,\n",
    "        headers = headers\n",
    "    )\n",
    "    \n",
    "    count = response.json()['data']['items'][0]['data']\n",
    "    dates = response.json()['data']['dates']\n",
    "    \n",
    "    active_user_time1 = pd.DataFrame( columns= ['date','count'])\n",
    "    active_user_time1.date = dates\n",
    "    active_user_time1['count'] = count\n",
    "    \n",
    "    active_user_time1[['Date','time']] = active_user_time1.date.str.split(expand=True) \n",
    "    \n",
    "    return active_user_time1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df(df1,df2):\n",
    "    df = df1.append(df2)\n",
    "    df.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\active_user_time.csv\",encoding = \"utf-8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这边建议将myMailBox改成MailTab\n",
    "\n",
    "name_dic_ios = {\n",
    "    'planetTab': '首页tab',\n",
    "    'explorTab': '想法tab',\n",
    "    'myMailBox': '信箱tab', \n",
    "    'momentTab': '瞬间tab',\n",
    "    'mineTab': '我的tab',\n",
    "    'planet_banner': \"首页里面的banner\",\n",
    "    'linesDairy': '首页里面的台历',\n",
    "    'programPlay': '首页里面的节目',\n",
    "    'rankingList': '首页里面的榜单',\n",
    "    'planet_hotTopic': \"首页里面的k星城邦\",\n",
    "    'filmListDetail': '首页里面的影单',\n",
    "    'goodFilmSearch':\"首页里面的好片库\",\n",
    "    'groupDetail': '城邦',\n",
    "    'privateMessage': '信箱里面的私信',\n",
    "    'filmDetail': '影片详情'，\n",
    "    \n",
    "    'thought': '一条想法',\n",
    "    'filmDetail': '电影详情',\n",
    "    'dairyCollectionList': '手账夹',\n",
    "    'linesDairyList': '台词日历列表',\n",
    "    'myViewHistory': '观影历史',\n",
    "    'planetTab_history': '观影历史',\n",
    "    'search': '搜索栏',\n",
    "    'share': '分享',\n",
    "    'programList': '节目列表',\n",
    "    'hotFilmList_banner': '热门影单banner',\n",
    "    'hotFilmList_normal': '热门影单普通',\n",
    "    'mineTab_myFilmList': '我的页面我的影单区域',\n",
    "    'mineTab_myFilmListCollection': '我的页面我收藏的影单区域',\n",
    "    'mineTab_myFilmListShare': '我的页面共享的影单区域',\n",
    "    'mineTab_recommend': '我的页面推荐影单',\n",
    "    'myFilmList': '我的影单页面',\n",
    "    'personalHomepage': '个人主页',\n",
    "    'planetTab_recommendForYou': 'k星球推荐',\n",
    "    'myGroups': '我的页面进我的城邦',\n",
    "    'explorTabTopic': '想法话题',\n",
    "    'thoughtsTag': '想法tag',\n",
    "    \"explorTabGroups_popular\":\"unknown\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dic_ios = {\n",
    "    'planetTab': '首页tab',\n",
    "    'explorTab': '想法tab',\n",
    "    'myMailBox': '信箱tab', \n",
    "    'momentTab': '瞬间tab',\n",
    "    'mineTab': '我的tab',\n",
    "    'planet_banner': \"首页里面的banner\",\n",
    "    'linesDairy': '首页里面的台历',\n",
    "    'programPlay': '首页里面的节目',\n",
    "    'rankingList': '首页里面的榜单',\n",
    "    'planet_hotTopic': \"首页里面的k星城邦\",\n",
    "    'filmListDetail': '首页里面的影单',\n",
    "    'goodFilmSearch':\"首页里面的好片库\",\n",
    "    'groupDetail': '城邦',\n",
    "    'privateMessage': '信箱里面的私信'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dic_android = {\n",
    "    'com.dianyingker.movie.module.common.MainActivity': '主页',\n",
    "    'com.dianyingker.movie.module.home.kstar.KStarOriginalDetailActivity': '节目',\n",
    "    'com.dianyingker.movie.module.home.detail.MovieDetailActivity': '影片详情',\n",
    "    'com.dianyingker.movie.module.account.message.ChatWithOfficialActivity': 'k小白私信',\n",
    "    'com.dianyingker.movie.module.account.person.HomePageActivity': '个人主页',\n",
    "    'com.dianyingker.movie.module.user.mine.MovieGroupDetailActivity': '影单'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_match_ios(s):\n",
    "    return input_dic_ios[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_match_Android(s):\n",
    "    return input_dic_android[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parentheses(s):\n",
    "    return s.split(\"(\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_parentheses2(s):\n",
    "    return s.split(\"秒(\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_percent_mark(s):\n",
    "    return s[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_overall_data(driver, dic_c, date3, platform):\n",
    "    '''\n",
    "    获取path的整体数据\n",
    "    '''\n",
    "    driver.get(\"https://mobile.umeng.com/platform/{}/function/path\".format(platform))\n",
    "    time.sleep(1)\n",
    "\n",
    "    for i in dic_c:\n",
    "        driver.add_cookie({'name':i,'value': dic_c[i]})\n",
    "    driver.refresh()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    date = driver.find_elements_by_class_name(\"um-ui-single-range-picker-text\")\n",
    "    date[0].click()\n",
    "    \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(Keys.CONTROL + \"a\") \n",
    "    driver.find_elements_by_class_name(\"ant-calendar-input\")[0].send_keys(date3[1])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    mouse_action = ActionChains(driver)\n",
    "    mouse_action.move_by_offset(xoffset = 0 , yoffset = 55).click().perform()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    head = driver.find_elements_by_class_name(\"ant-table-column-title\")\n",
    "    header_list = [i.text for i in head]\n",
    "    \n",
    "    path_overall = pd.DataFrame( columns= header_list[:-3])\n",
    "    \n",
    "    data = driver.find_elements_by_class_name(\"ant-table-row\")\n",
    "    \n",
    "    for i in data:\n",
    "        a = i.text\n",
    "        l = a.split(\" \")\n",
    "        l1 = l[:3]\n",
    "        l2 = l[-1]\n",
    "        a = \"\".join(l[3:5])\n",
    "        l1.append(a)\n",
    "        l1.append(l2)\n",
    "        path_overall.loc[len(path_overall)] = l1\n",
    "        \n",
    "    if platform == \"5cbd86bd570df3cf0a0009ee\":\n",
    "        #print(\"this is for ios\")\n",
    "        path_overall = path_overall[path_overall.描述.isin(list(input_dic_ios.keys()))]\n",
    "        path_overall['描述'] = path_overall.描述.apply(name_match_ios)\n",
    "    else:\n",
    "        path_overall = path_overall[path_overall.描述.isin(list(input_dic_android.keys()))]\n",
    "        #print(\"this is for Android\")\n",
    "        path_overall['描述'] = path_overall.描述.apply(name_match_Android)\n",
    "        \n",
    "     \n",
    "    path_overall['访问次数'] = path_overall[\"访问次数(占比)\"].apply(remove_parentheses)\n",
    "    path_overall['平均访问时长'] = path_overall[\"平均访问时长(占比)\"].apply(remove_parentheses2)\n",
    "    path_overall['跳出率'] = path_overall[\"跳出率\"].apply(remove_percent_mark)\n",
    "    path_overall = path_overall[['页面(Activity/Fragment)','描述','访问次数','平均访问时长','跳出率']]\n",
    "         \n",
    "    path_overall.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\path_{}.csv\".format(date3[1]),encoding = \"utf-8_sig\")\n",
    "        \n",
    "        \n",
    "       \n",
    "    return \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_detail(driver, dic_c, date1, date2, platform):\n",
    "    '''\n",
    "    get all the detail path information\n",
    "    '''\n",
    "    \n",
    "    driver.get(\"https://mobile.umeng.com/platform/{}/function/events/dashboard\".format(platform))\n",
    "    time.sleep(1)\n",
    "\n",
    "    for i in dic_c:\n",
    "        driver.add_cookie({'name':i,'value': dic_c[i]})\n",
    "    driver.refresh()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    return\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(s,date1,date2,platform):\n",
    "    '''\n",
    "    get all the data includes:\n",
    "        1. total trend\n",
    "        2. new user stay\n",
    "        3. active user stay\n",
    "        4. device\n",
    "        5. country\n",
    "        6. location\n",
    "        7. active time in hour\n",
    "    '''\n",
    "    driver = open_window()\n",
    "    #填写你网站的cookie\n",
    "    #填写你想获取的两周时间段\n",
    "\n",
    "    dic_c = get_cookie_dic(s)\n",
    "\n",
    "    \n",
    "    #下载两周的总体趋势（total_trend.csv）\n",
    "    get_total_trend(driver, dic_c , date1, date2, platform)\n",
    "\n",
    "    #下载两周(新用户+活跃用户）留存 (new_use_stay.csv, active_user_stay.csv)\n",
    "    get_user_stay(driver, dic_c, date1, date2, platform)\n",
    "\n",
    "    #下载两周device的数据信息 (device.csv\n",
    "    get_device(driver,dic_c, date1, date2, platform)\n",
    "\n",
    "    #下载两周省份和国家的数据信息（province.csv, country.csv)\n",
    "    get_location(driver, dic_c, date1, date2, platform)\n",
    "\n",
    "    #下载两周的活跃时间\n",
    "    combine_df(get_active_user_time(driver, dic_c, date1, platform),get_active_user_time(driver, dic_c, date2, platform))\n",
    "    \n",
    "    get_path_overall_data(driver, dic_c, date1, platform)\n",
    "    get_path_overall_data(driver, dic_c, date2, platform)\n",
    "    \n",
    "    #get_path_detail(driver, dic_c, date1, date2, platform)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back-end Data\n",
    "\n",
    "### 目前后台的数据缺少： 整体新增（这个需要手动）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBetweenDay(begin_date,end_date):\n",
    "    '''\n",
    "    get date between begin_date and end_date (included)\n",
    "    '''\n",
    "    date_list = []\n",
    "    begin_date = datetime.datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    while begin_date <= end_date:\n",
    "        date_str = begin_date.strftime(\"%Y-%m-%d\")\n",
    "        date_list.append(date_str)\n",
    "        begin_date += datetime.timedelta(days=1)\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cb_data(cookie, date1, date2, dic_h):\n",
    "    '''\n",
    "    get cb data for two weeks\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame( columns= ['#', '城邦ID', '邦主头像', '邦主昵称', '创建人头像', '创建人昵称', '创建时间', '城邦类型', '城邦', '阅读量', '想法量', '订阅量', '是否精选', '是否上首页', '操作'])\n",
    "    count = 1\n",
    "    r = requests.get('https://www.dianyingker.com/adminpanel/topic/index/{}?time_1={}+&time_2={}+&is_selected=0&is_go_home=0&keyword=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count, date1[0],date2[1]), headers = dic_h , cookies = cookie)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    print(\"download page 1 ...\")\n",
    "    while soup.find(\"a\", class_ = \"nextpage\") != None:\n",
    "        tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "        for j in range(1,len(tr_list)):\n",
    "            row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "            df.loc[len(df)] = row\n",
    "        count += 1\n",
    "        print(\"download page {} ...\".format(count))\n",
    "        r = requests.get('https://www.dianyingker.com/adminpanel/topic/index/{}?time_1={}+&time_2={}+&is_selected=0&is_go_home=0&keyword=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count,date1[0],date2[1] ), headers = dic_h , cookies = cookie)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        \n",
    "    tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "    for j in range(1,len(tr_list)):\n",
    "        row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "        df.loc[len(df)] = row\n",
    "            \n",
    "    df.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\cb.csv\",encoding = \"utf-8_sig\")\n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yd_data(cookie, date1, date2, dic_h):\n",
    "    '''\n",
    "    get cb data for two weeks\n",
    "    '''\n",
    "        \n",
    "    df = pd.DataFrame( columns= ['#', 'ID', '头像', '昵称', '创建时间', '名称', '描述', '横向封面', '共享量', '收藏量', '查看量', '影片量', '电影', '操作'])\n",
    "    count = 1\n",
    "    r = requests.get('https://www.dianyingker.com/adminpanel/movieGroup/index/{}?time_1={}&time_2={}&min_num=&max_num=&is_selected=0&is_go_home=0&is_hcover=0&keyword=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count, date1[0],date2[1]), headers = dic_h , cookies = cookie)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    print(\"download page 1 ...\")\n",
    "    while soup.find(\"a\", class_ = \"nextpage\") != None:\n",
    "        tr_list = soup.find(\"table\",id=\"datalist\").find_all('tr')\n",
    "        for j in range(1,len(tr_list)):\n",
    "            row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "            df.loc[len(df)] = row\n",
    "        count += 1\n",
    "        print(\"download page {} ...\".format(count))\n",
    "        r = requests.get('https://www.dianyingker.com/adminpanel/movieGroup/index/{}?time_1={}&time_2={}&min_num=&max_num=&is_selected=0&is_go_home=0&is_hcover=0&keyword=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count,date1[0],date2[1] ), headers = dic_h , cookies = cookie)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        \n",
    "    \n",
    "    tr_list = soup.find(\"table\",id=\"datalist\").find_all('tr')\n",
    "    for j in range(1,len(tr_list)):\n",
    "        row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "        df.loc[len(df)] = row\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\yd.csv\",encoding = \"utf-8_sig\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jspl_data(cookie, date1, date2, dic_h):\n",
    "    '''\n",
    "    获取解说评论数据\n",
    "    '''\n",
    "    df = pd.DataFrame( columns= ['#', '评论ID', '粉丝头像', '粉丝', '评论时间', '视频', '节目编号', '评论', '点赞数', '置顶', '删除', '操作'])\n",
    "    count = 1\n",
    "    r = requests.get('https://www.dianyingker.com/adminpanel/comment/index/{}?time_1={}&time_2={}&is_top=-1&is_deleted=-1&keyword=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count, date1[0],date2[1]), headers = dic_h , cookies = cookie)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    print(\"download page 1 ...\")\n",
    "    while soup.find(\"a\", class_ = \"nextpage\") != None:\n",
    "        tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "        for j in range(1,len(tr_list)):\n",
    "            row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "            df.loc[len(df)] = row\n",
    "        count += 1\n",
    "        print(\"download page {} ...\".format(count))\n",
    "        r = requests.get('https://www.dianyingker.com/adminpanel/comment/index/{}?time_1={}&time_2={}&is_top=-1&is_deleted=-1&keyword=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count,date1[0],date2[1] ), headers = dic_h , cookies = cookie)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        \n",
    "    \n",
    "    tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "    for j in range(1,len(tr_list)):\n",
    "        row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "        df.loc[len(df)] = row\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\jspl.csv\",encoding = \"utf-8_sig\")\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xflb_data(cookie, date1, date2, dic_h):\n",
    "    '''\n",
    "    获取想法列表数据\n",
    "    '''\n",
    "    df = pd.DataFrame( columns= ['#', '想法ID', '头像', '昵称', '想法类型', '内容', '权限设置', '城邦', '评论量', '点赞量', '发布时间', '操作'])\n",
    "    count = 1\n",
    "    r = requests.get('https://www.dianyingker.com/adminpanel/dynamic/index/{}?time_1={}&time_2={}&is_deleted=0&is_selected=0&is_go_home=0&keyword=&topic=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count, date1[0],date2[1]), headers = dic_h , cookies = cookie)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    print(\"download page 1 ...\")\n",
    "    while soup.find(\"a\", class_ = \"nextpage\") != None:\n",
    "        tr_list = soup.find(\"table\",id=\"datalist\").find_all('tr')\n",
    "        for j in range(1,len(tr_list)):\n",
    "            row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "            df.loc[len(df)] = row\n",
    "        count += 1\n",
    "        print(\"download page {} ...\".format(count))\n",
    "        r = requests.get('https://www.dianyingker.com/adminpanel/dynamic/index/{}?time_1={}&time_2={}&is_deleted=0&is_selected=0&is_go_home=0&keyword=&topic=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count,date1[0],date2[1] ), headers = dic_h , cookies = cookie)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        \n",
    "    \n",
    "    tr_list = soup.find(\"table\",id=\"datalist\").find_all('tr')\n",
    "    for j in range(1,len(tr_list)):\n",
    "        row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "        df.loc[len(df)] = row\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\xflb.csv\",encoding = \"utf-8_sig\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tcdm_data(cookie, date1,date2, dic_h):\n",
    "    '''\n",
    "    获取台词日历弹幕\n",
    "    '''\n",
    "        \n",
    "    df = pd.DataFrame( columns= ['#', '日历', '粉丝头像', '粉丝昵称', '日历日期', '台词', '弹幕内容', '弹幕发送时间', '操作'])\n",
    "    count = 1\n",
    "    r = requests.get('https://www.dianyingker.com/adminpanel/barrage/index/{}?keyword=&day=&time_1={}&time_2={}&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "        .format(count, date1[0],date2[1]), headers = dic_h , cookies = cookie)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    print(\"download page 1 ...\")\n",
    "    while soup.find(\"a\", class_ = \"nextpage\") != None:\n",
    "        tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "        for j in range(1,len(tr_list)):\n",
    "            row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "            df.loc[len(df)] = row\n",
    "        count += 1\n",
    "        print(\"download page {} ...\".format(count))\n",
    "        r = requests.get('https://www.dianyingker.com/adminpanel/barrage/index/{}?keyword=&day=&time_1={}&time_2={}&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "            .format(count, date1[0],date2[1]), headers = dic_h , cookies = cookie)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        \n",
    "    \n",
    "    tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "    for j in range(1,len(tr_list)):\n",
    "        row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "        df.loc[len(df)] = row\n",
    "    \n",
    "            \n",
    "    df.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\tcdm.csv\",encoding = \"utf-8_sig\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jsdm_data(cookie, date1, date2, dic_h):\n",
    "    '''\n",
    "    获取解说弹幕\n",
    "    '''\n",
    "    df = pd.DataFrame( columns= ['#', '粉丝头像', '粉丝', '弹幕发送时间', '视频名', '弹幕内容', '弹幕颜色', '操作'])\n",
    "    count = 1\n",
    "    r = requests.get('https://www.dianyingker.com/adminpanel/movieBarrage/index/{}?keyword=&time_1={}&time_2={}&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count, date1[0],date2[1]), headers = dic_h , cookies = cookie)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    print(\"download page 1 ...\")\n",
    "    while soup.find(\"a\", class_ = \"nextpage\") != None:\n",
    "        tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "        for j in range(1,len(tr_list)):\n",
    "            row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "            df.loc[len(df)] = row\n",
    "        count += 1\n",
    "        print(\"download page {} ...\".format(count))\n",
    "        r = requests.get('https://www.dianyingker.com/adminpanel/movieBarrage/index/{}?keyword=&time_1={}&time_2={}&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count,date1[0],date2[1] ), headers = dic_h , cookies = cookie)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        \n",
    "    \n",
    "    tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "    for j in range(1,len(tr_list)):\n",
    "        row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "        df.loc[len(df)] = row\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\jsdm.csv\",encoding = \"utf-8_sig\")\n",
    "    \n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yppl_data(cookie, date1, date2, dic_h):\n",
    "    '''\n",
    "    获取影片评论弹幕\n",
    "    '''\n",
    "    df = pd.DataFrame( columns= ['#', '评论ID', '粉丝头像', '粉丝', '评论时间', '视频', '打分', '评论', '点赞数', '置顶', '删除', '操作'])\n",
    "    count = 1\n",
    "    r = requests.get('https://www.dianyingker.com/adminpanel/comment/film/{}?time_1={}+&time_2={}+&is_top=-1&is_deleted=-1&keyword=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count, date1[0],date2[1]), headers = dic_h , cookies = cookie)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    print(\"download page 1 ...\")\n",
    "    while soup.find(\"a\", class_ = \"nextpage\") != None:\n",
    "        tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "        tr_list2 = tr_list[1::3]\n",
    "        for i in tr_list2:\n",
    "            cols = i.find_all('td')\n",
    "            rows = [x.text.strip() for x in cols]\n",
    "            rows2 = rows[:7]+(rows[-5:])\n",
    "            df.loc[len(df)] = rows2\n",
    "        count += 1\n",
    "        print(\"download page {} ...\".format(count))\n",
    "        r = requests.get('https://www.dianyingker.com/adminpanel/comment/film/{}?time_1={}+&time_2={}+&is_top=-1&is_deleted=-1&keyword=&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count,date1[0],date2[1] ), headers = dic_h , cookies = cookie)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        \n",
    "    \n",
    "    tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "    tr_list2 = tr_list[1::3]\n",
    "    for i in tr_list2:\n",
    "        cols = i.find_all('td')\n",
    "        rows = [x.text.strip() for x in cols]\n",
    "        rows2 = rows[:7]+(rows[-5:])\n",
    "        df.loc[len(df)] = rows2\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\yppl.csv\",encoding = \"utf-8_sig\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xfpl_data(cookie, date1, date2, dic_h):\n",
    "    '''\n",
    "    获取想法评论数据\n",
    "    '''\n",
    "    df = pd.DataFrame( columns= ['#', '评论ID', '粉丝头像', '粉丝', '评论时间', '想法', '评论', '点赞数', '删除', '回复', '操作'])\n",
    "    count = 1\n",
    "    r = requests.get('https://www.dianyingker.com/adminpanel/comment/dynamic/{}?keyword=&time_1={}&time_2={}&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count, date1[0],date2[1]), headers = dic_h , cookies = cookie)\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "    print(\"download page 1 ...\")\n",
    "    while soup.find(\"a\", class_ = \"nextpage\") != None:\n",
    "        tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "        for j in range(1,len(tr_list)):\n",
    "            row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "            df.loc[len(df)] = row\n",
    "        count += 1\n",
    "        print(\"download page {} ...\".format(count))\n",
    "        r = requests.get('https://www.dianyingker.com/adminpanel/comment/dynamic/{}?keyword=&time_1={}&time_2={}&dosubmit=%E6%90%9C%E7%B4%A2'\n",
    "                              .format(count,date1[0],date2[1] ), headers = dic_h , cookies = cookie)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        \n",
    "    \n",
    "    tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "    for j in range(1,len(tr_list)):\n",
    "        row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "        df.loc[len(df)] = row\n",
    "    \n",
    "    df.to_csv(\"C:\\\\Users\\\\Ker\\\\Desktop\\\\xfpl.csv\",encoding = \"utf-8_sig\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_user_data(cookie, date1, date2, dic_h ):\n",
    "    '''\n",
    "    获取新用户数据\n",
    "    '''\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_backend_data(cookie, date1, date2, dic_h):\n",
    "    '''\n",
    "    get all back end data together\n",
    "    '''\n",
    "    \n",
    "    # 城邦数据\n",
    "    print(\"start with 城邦 data ...\")\n",
    "    get_cb_data(cookie, date1, date2, dic_h)\n",
    "    print(\"end with 城邦 data ...\")\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    # 影单数据\n",
    "    print(\"start with 影单 data ...\")\n",
    "    get_yd_data(cookie, date1, date2, dic_h)\n",
    "    print(\"end with 影单 data ...\")\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    # 解说评论\n",
    "    print(\"start with 解说评论 data ...\")\n",
    "    get_jspl_data(cookie, date1, date2, dic_h)\n",
    "    print(\"end with 解说评论 data ...\")\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    # 想法列表\n",
    "    print(\"start with 想法列表 data ...\")\n",
    "    get_xflb_data(cookie, date1, date2, dic_h)\n",
    "    print(\"end with 想法列表 data ...\")\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    # 台词弹幕\n",
    "    print(\"start with 台词弹幕 data ...\")\n",
    "    get_tcdm_data(cookie, date1,date2, dic_h)\n",
    "    print(\"end with 台词弹幕 data ...\")\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    # 解说弹幕\n",
    "    print(\"start with 解说弹幕 data ...\")\n",
    "    get_jsdm_data(cookie, date1, date2, dic_h)\n",
    "    print(\"end with 解说弹幕 data ...\")\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    # 影片评论\n",
    "    print(\"start with 影片评论 data ...\")\n",
    "    get_yppl_data(cookie, date1, date2, dic_h)\n",
    "    print(\"end with 影片评论 data ...\")\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    # 想法评论\n",
    "    print(\"start with 想法评论 data ...\")\n",
    "    get_xfpl_data(cookie, date1, date2, dic_h)\n",
    "    print(\"end with 想法评论 data ...\")\n",
    "    print(\"-------------------------------\")\n",
    "    \n",
    "    \n",
    "    # 新增用户\n",
    "    print(\"start with 新增用户 data ...\")\n",
    "    get_new_user_data(cookie, date1, date2, dic_h)\n",
    "    print(\"end with 想法评论 data ...\")\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_user_info(startpage, endpage):\n",
    "    '''\n",
    "    get new user register time information from backend data for 14 days (from 2020-08-02 to 2020-08-15)\n",
    "    n is the page \n",
    "    '''\n",
    "    df = pd.DataFrame( columns= ['#', '用户ID', '用户头像', '昵称', '邀请码', '手机号码', '是否黑名单', '是否内部员工', '是否运营号', '是否终身会员', '注册APP时间', '最近一条消息', '操作'])\n",
    "    for i in range(startpage,endpage+1):\n",
    "        print(\"start download {} page ...\".format(i))\n",
    "        r = requests.get(\"https://www.dianyingker.com/adminpanel/fans/index/{}?order=register_time_in_app&dir=desc\".format(i), headers = headers , cookies = s)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        tr_list = soup.find(\"table\",id=\"checkAll\").find_all('tr')\n",
    "        for j in range(1,len(tr_list)):\n",
    "            row = [x.text.strip() for x in tr_list[j].find_all('td')]\n",
    "            df.loc[len(df)] = row\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which dates you wanna scrape the data\n",
    "date1 = ['2020-08-16','2020-08-22']\n",
    "date2 = ['2020-08-23','2020-08-29']\n",
    "\n",
    "# s1 -> ios cookie \n",
    "s1 = \"UM_distinctid=173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465; dplus_cross_id=173e12506d628c-06078ac4c8da6f-3323767-1fa400-173e12506d759e; dplus_finger_print=2822180395; cna=Omy6F8MK9Q0CARsRIOYQfmm8; uc_session_id=973cf1ce-0641-40d4-984c-e6e9e1b4cb88; umplus_uc_loginid=kdylm; cn_1271885898_dplus=1%5B%7B%22userid%22%3A%22kdylm%22%2C%22AppKey%22%3A%225cbd86bd570df3cf0a0009ee%22%7D%2C0%2C1597977420%2C0%2C1597977420%2Cnull%2C%22173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465%22%2C%221597285046%22%2C%22https%3A%2F%2Fworkbench.umeng.com%2F%22%2C%22workbench.umeng.com%22%5D; umplus_uc_token=1SG7yAOH25SI32wcCDFEHpg_62aad45450274e1d92ae5b255e088713; Hm_lvt_289016bc8d714b0144dc729f1f2ddc0d=1598508153,1598508271,1598581271,1598923938; XSRF-TOKEN=180ef43b-dc03-4746-9e15-b7d856a07d27; XSRF-TOKEN-HAITANG=9286eca8-5ecc-4e77-b073-6bc66f958692; Hm_lpvt_289016bc8d714b0144dc729f1f2ddc0d=1598924867; cn_1258498910_dplus=1%5B%7B%22utm_source%22%3A%22n_uapp_top_pc_c%22%2C%22userid%22%3A%22kdylm%22%7D%2C0%2C1598924868%2C0%2C1598924868%2C%22%24direct%22%2C%22173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465%22%2C%221597207562%22%2C%22https%3A%2F%2Fwww.google.com%2F%22%2C%22www.google.com%22%5D; EGG_SESS=_GOCmDZcFN18IbC7Ny32_jE4YaQ_aYwZxhPACRjThr8yPAC3cAv-zhtTdnQpsB0Dgf5MCX_hizRFzqXCI0-i1W6kEvgqNBcyquRYqxn3KsYH4kK-XGNXZ5xJb8GVZKL4QDbn6FvQ9YALpDtZrtHjTPFgEETMFJ52MuXnUAgcrhZJgss19PD4eQomFH0iMpMxJ-4N3n-fiovISjKRg4u6sjOCOGVALRwMWhytWABECUP7rd_5q3QgQX5yCdD3mW4IkfL8Sv4Yahd8ivC2ga8HQm5ezyk1MZ7OY6FtSJR3qpY2mOSxbDnt5pOFS9Q6c2BoFdoE8iRhsQHzf8feqLp5jI1Zzgpp3nJIelCLYNQ1XN94Iogghm_61-WQ8yQlX_mANfNz28p_E5GLk11jxjMre79b28qd6gr1vILQ95SXH5C1Rw5W3-9q5PnK1lNKenUpQM4KcShEJgTmRLepB7Excp0TZHim2mdSdB7rhUp0SV3xW3M3-W3Oebi_ygoGTBwB6xDSneXT2oKr2IVa1IkHxyuVNv6CTNI1NMSEcT38X_72WL5otovJYUgiWoQzR0Q0aPgYXKEFFM8wdkUA-dT3MXXamCeXTz6P2FTqMwMdCdHhx0-xE84rehl00Ds8y3GdEtuncuInQIGIoObSvh6Yzq2HsIKYvl2l6HmNepmbA5gAJ7-X12d_-zMuTteubqz43sQNSo30cWAOCKRLdh0DIewci8uR5u4HDIqKU5qx9gk=; cn_1273967994_dplus=1%5B%7B%7D%2Cnull%2Cnull%2Cnull%2Cnull%2C%22%24direct%22%2C%22173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465%22%2C%221597209918%22%2C%22https%3A%2F%2Fworkbench.umeng.com%2F%3Fspm%3Da213m0.13887608.0.0.3cb275efYgGziK%22%2C%22workbench.umeng.com%22%5D; CNZZDATA1259864772=449313210-1597209918-https%253A%252F%252Fworkbench.umeng.com%252F%7C1598933903; isg=BGVlStPVVikPt7KLqcGHFfb1dCGfohk0vt7zSWdPURynfpXwL_TBBAJfDOII_jHs; cn_1259864772_dplus=1%5B%7B%22Uapp_appkey%22%3A%225cbd86bd570df3cf0a0009ee%22%2C%22Uapp_platform%22%3A%22iphone%22%2C%22UserID%22%3A%22kdylm%22%7D%2C0%2C1598938296%2C0%2C1598938296%2C%22%24direct%22%2C%22173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465%22%2C%221597209918%22%2C%22https%3A%2F%2Fworkbench.umeng.com%2F%3Fspm%3Da213m0.13887608.0.0.3cb275efYgGziK%22%2C%22workbench.umeng.com%22%5D\"\n",
    "sios = \"5cbd86bd570df3cf0a0009ee\"\n",
    "\n",
    "# s2 -> Android cookie\n",
    "s2 = \"UM_distinctid=173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465; dplus_cross_id=173e12506d628c-06078ac4c8da6f-3323767-1fa400-173e12506d759e; dplus_finger_print=2822180395; cna=Omy6F8MK9Q0CARsRIOYQfmm8; uc_session_id=973cf1ce-0641-40d4-984c-e6e9e1b4cb88; umplus_uc_loginid=kdylm; cn_1271885898_dplus=1%5B%7B%22userid%22%3A%22kdylm%22%2C%22AppKey%22%3A%225cbd86bd570df3cf0a0009ee%22%7D%2C0%2C1597977420%2C0%2C1597977420%2Cnull%2C%22173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465%22%2C%221597285046%22%2C%22https%3A%2F%2Fworkbench.umeng.com%2F%22%2C%22workbench.umeng.com%22%5D; umplus_uc_token=1SG7yAOH25SI32wcCDFEHpg_62aad45450274e1d92ae5b255e088713; EGG_SESS=_GOCmDZcFN18IbC7Ny32_jE4YaQ_aYwZxhPACRjThr8yPAC3cAv-zhtTdnQpsB0Dgf5MCX_hizRFzqXCI0-i1W6kEvgqNBcyquRYqxn3KsYH4kK-XGNXZ5xJb8GVZKL4QDbn6FvQ9YALpDtZrtHjTPFgEETMFJ52MuXnUAgcrhZJgss19PD4eQomFH0iMpMxJ-4N3n-fiovISjKRg4u6sjOCOGVALRwMWhytWABECUP7rd_5q3QgQX5yCdD3mW4IkfL8Sv4Yahd8ivC2ga8HQm5ezyk1MZ7OY6FtSJR3qpY2mOSxbDnt5pOFS9Q6c2BoFdoE8iRhsQHzf8feqLp5jI1Zzgpp3nJIelCLYNQ1XN94Iogghm_61-WQ8yQlX_mANfNz28p_E5GLk11jxjMre79b28qd6gr1vILQ95SXH5C1Rw5W3-9q5PnK1lNKenUpQM4KcShEJgTmRLepB7Excp0TZHim2mdSdB7rhUp0SV3xW3M3-W3Oebi_ygoGTBwB6xDSneXT2oKr2IVa1IkHxyuVNv6CTNI1NMSEcT38X_72WL5otovJYUgiWoQzR0Q0aPgYXKEFFM8wdkUA-dT3MXXamCeXTz6P2FTqMwMdCdHhx0-xE84rehl00Ds8y3GdEtuncuInQIGIoObSvh6Yzq2HsIKYvl2l6HmNepmbA5jRdg06r4E9C5Oj85xnixnaOEXdnpi4gvr2JL6AHzxP0Y2KbMHp_dA7Pyn1bYJ3WEo=; Hm_lvt_289016bc8d714b0144dc729f1f2ddc0d=1598508153,1598508271,1598581271,1598923938; CNZZDATA1259864772=449313210-1597209918-https%253A%252F%252Fworkbench.umeng.com%252F%7C1598920258; XSRF-TOKEN=180ef43b-dc03-4746-9e15-b7d856a07d27; XSRF-TOKEN-HAITANG=9286eca8-5ecc-4e77-b073-6bc66f958692; Hm_lpvt_289016bc8d714b0144dc729f1f2ddc0d=1598924867; cn_1258498910_dplus=1%5B%7B%22utm_source%22%3A%22n_uapp_top_pc_c%22%2C%22userid%22%3A%22kdylm%22%7D%2C0%2C1598924868%2C0%2C1598924868%2C%22%24direct%22%2C%22173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465%22%2C%221597207562%22%2C%22https%3A%2F%2Fwww.google.com%2F%22%2C%22www.google.com%22%5D; cn_1259864772_dplus=1%5B%7B%22Uapp_appkey%22%3A%225cbd86520cafb282c9000f14%22%2C%22Uapp_platform%22%3A%22android%22%2C%22UserID%22%3A%22kdylm%22%7D%2C0%2C1598925419%2C0%2C1598925419%2C%22%24direct%22%2C%22173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465%22%2C%221597209918%22%2C%22https%3A%2F%2Fworkbench.umeng.com%2F%3Fspm%3Da213m0.13887608.0.0.3cb275efYgGziK%22%2C%22workbench.umeng.com%22%5D; cn_1273967994_dplus=1%5B%7B%7D%2Cnull%2Cnull%2Cnull%2Cnull%2C%22%24direct%22%2C%22173e12506d2565-0760ced0230ae4-3323767-1fa400-173e12506d3465%22%2C%221597209918%22%2C%22https%3A%2F%2Fworkbench.umeng.com%2F%3Fspm%3Da213m0.13887608.0.0.3cb275efYgGziK%22%2C%22workbench.umeng.com%22%5D; isg=BJGR0mb_qu21TMaHne3rUQoRoJ0r_gVwN2whYHMmsdh3GrBsu0x5QNd8vO78Ep2o\"\n",
    "sAndroid = \"5cbd86520cafb282c9000f14\"\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "#s -> backend cookie \n",
    "\n",
    "s = {\"autocodeigniter_com\":\"1cakpn78ptacqs71v1ap3og6jqbki2fa\"}\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 后台数据\n",
    "get_all_backend_data(s, date1, date2, headers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ios data:\n",
    "get_all_data(s1,date1,date2,sios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't start IOS and Android download together because they have same .csv name\n",
    "### ONLY start Android after locating IOS data in the corresponding folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Andriod data:\n",
    "get_all_data(s2,date1,date2,sAndroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
