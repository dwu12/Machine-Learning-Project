{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc215b0-283b-4131-96d5-3ff4162408cd",
   "metadata": {},
   "source": [
    "# HIE Outcome Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b20cf-6369-4996-af1e-c19c9b1f6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up dependency(s)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import vstack\n",
    "from numpy import hstack\n",
    "from numpy import asarray\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "## plot method\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator,IndexLocator\n",
    "import seaborn as sns\n",
    "\n",
    "## Image and HTML\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from IPython.display import display\n",
    "\n",
    "   \n",
    "## Metices\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# SKlearn Models\n",
    "from sklearn import tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## feature ranking\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "import itertools\n",
    "\n",
    "import multiprocess as mp\n",
    "\n",
    "## Boosting Method\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## regex \n",
    "import re\n",
    "\n",
    "## resample technique\n",
    "from sklearn.utils import resample\n",
    "\n",
    "## time \n",
    "import time\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c55c3-2174-480b-99d7-5567ed8a0819",
   "metadata": {},
   "source": [
    "## Define Functions Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f5d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(df, \n",
    "             target, \n",
    "             Flag = False, \n",
    "             ratio = 1, \n",
    "             random_state = 42, \n",
    "             replace = True):\n",
    "    \n",
    "    '''\n",
    "    Designed for imbalanced dataset, use upsampling techniques to make target distribution \n",
    "    in some specific ratio, default ratio is 1 meaning all target values equally distributed\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe you want to make upsampling (for imbalanced dataset)\n",
    "        \n",
    "    target: target column for upsampling\n",
    "    \n",
    "    Flag: whether print the original target distribution, default is False\n",
    "    \n",
    "    Ratio: ratio of majority / minority, default is 1\n",
    "    \n",
    "    random_state: for reproducible, default is 42\n",
    "    \n",
    "    replace: sample with replacement or not, default is True\n",
    "    ----------\n",
    "    \n",
    "    returns : a dataset with specific ration for target distribution\n",
    "    '''\n",
    "    \n",
    "    if Flag:\n",
    "        plt.figure(figsize=(8,4)) \n",
    "        ax = sns.countplot(x= target , data=df)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "        ax.set_title('How many counts for categorical feature: {}'.format(target))\n",
    "\n",
    "    value_dic = df[target].value_counts()\n",
    "    target_value = value_dic.keys()\n",
    "    \n",
    "    majority = target_value[0]\n",
    "    majority_value = value_dic[majority]\n",
    "    \n",
    "    df_majority = df[(df[target]==majority)] \n",
    "    \n",
    "    l = [df_majority]\n",
    "    \n",
    "    for minority in target_value[1:]:\n",
    "        df_minority = df[(df[target] == minority)] \n",
    "\n",
    "        df_minority_upsampled = resample(df_minority, \n",
    "                                         replace=replace,    # sample with replacement\n",
    "                                         n_samples= majority_value // ratio, # to match majority class\n",
    "                                         random_state=random_state)  # reproducible results\n",
    "        \n",
    "        l.append(df_minority_upsampled)\n",
    "         \n",
    "    \n",
    "    output = pd.concat(l)\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def Fibe(estimator_name, \n",
    "         estimator, \n",
    "         X, \n",
    "         y, \n",
    "         score_metric, \n",
    "         feature_groups, \n",
    "         cv = 5, \n",
    "         Flag= False, \n",
    "         threshold = False):\n",
    "    \n",
    "    '''\n",
    "    Designed for FIBE (Forward Inclusion Backward Elimination) method to find the best feature \n",
    "    combination. For more info: please check: \n",
    "    \n",
    "    http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator_name: the name of estimator, could be classification | regression estimator\n",
    "        \n",
    "    estimator: machine learning estimator\n",
    "    \n",
    "    X: used for model training\n",
    "    \n",
    "    y: used for model training\n",
    "    \n",
    "    score_metric: offline metric, can be either classification or regression\n",
    "    \n",
    "    feature_groups: group features for better explanation. The idea is group one-hot encoder features together.\n",
    "                    default is None\n",
    "                    \n",
    "    cv: cross validation, default = 5\n",
    "    \n",
    "    Flag: print detail information, default = False\n",
    "    \n",
    "    threshold: set a threshold for max # number of features you want select, default = False\n",
    "    \n",
    "    ----------\n",
    "    \n",
    "    returns : a pair of ([selected features], estimator name)\n",
    "    '''\n",
    "    \n",
    "    num_features = len(feature_groups)\n",
    "    \n",
    "    if threshold != None:\n",
    "        num_features = threshold\n",
    "    \n",
    "    sff_clf = SFS(estimator,\n",
    "                  k_features=(1, num_features),\n",
    "                  forward=True,\n",
    "                  floating=True,\n",
    "                  scoring= score_metric,\n",
    "                  feature_groups = feature_groups,\n",
    "                  cv=cv)\n",
    "    \n",
    "    sff_clf.fit(X, y)\n",
    "    \n",
    "    if Flag:\n",
    "        print('best combination (%s: %.3f): %s\\n' % (score_metric, sff_clf.k_score_, sff_clf.k_feature_idx_))\n",
    "        print('all subsets:\\n', sff_clf.subsets_)\n",
    "        \n",
    "    return (list(sff_clf.k_feature_names_), estimator_name)\n",
    "\n",
    "\n",
    "def check_balance(df, target):\n",
    "    '''\n",
    "    check a dataset has balanced distribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe you want to make upsampling (for imbalanced dataset)\n",
    "        \n",
    "    target: target column balance checking\n",
    "    ----------\n",
    "    \n",
    "    returns : True if balanced distribution else false\n",
    "    '''\n",
    "    \n",
    "    l = df[target].value_counts().tolist()\n",
    "    max_val = np.max(l)\n",
    "    min_val = np.min(l)\n",
    "    \n",
    "    return (max_val / min_val) <= 3\n",
    "    \n",
    "\n",
    "\n",
    "def get_feature_dic(method_dic,\n",
    "                    df_train, \n",
    "                    target , \n",
    "                    score_metric,\n",
    "                    cv = 5,\n",
    "                    upsample_flag = False,\n",
    "                    upsample_flag_show = False, \n",
    "                    ratio = 1, \n",
    "                    random_state = 42, \n",
    "                    replace = True ,\n",
    "                    feature_groups = None, \n",
    "                    fibe_cv = 3,\n",
    "                    fibe_flag_show = False,\n",
    "                    Threshold = None\n",
    "                    ):\n",
    "    \n",
    "    '''\n",
    "    get the FIBE information for different methods\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    method_dic: a dictionary with the format key = estimator name, value = estimator\n",
    "    \n",
    "    df_train: dataframe for training \n",
    "    \n",
    "    df_test: dataframe for testing, if df_y is None, then df_x will be split to train-test dataset using cross-validation\n",
    "    \n",
    "    target: target feature using on both df_x and df_y\n",
    "    \n",
    "    score_metric: offline metric for Fibe Method, can be either classification or regression\n",
    "    \n",
    "    cv = 5: default equal to 5 for cross-validation if df_test is None\n",
    "    \n",
    "    upsamle_flag: if True, use upsample method, default False \n",
    "    \n",
    "    upsample_flag_show: if True, show the target distribution, default False\n",
    "    \n",
    "    Ratio: ratio of majority / minority, default is 1\n",
    "    \n",
    "    random_state: for reproducible, default is 42\n",
    "    \n",
    "    replace: sample with replacement or not, default is True\n",
    "    \n",
    "    feature_groups: group features for better explanation. The idea is group one-hot encoder features together.\n",
    "                    default is None\n",
    "    \n",
    "    fibe_cv: cross validation, default = 5\n",
    "    \n",
    "    fibe_flag_show: print detail information, default = False\n",
    "    \n",
    "    threshold: set a threshold for max # number of features you want select, default = False\n",
    "    \n",
    "    \n",
    "    ----------\n",
    "    \n",
    "    returns : A list contains [ (estimator_name, feature_selected, scoring)]\n",
    "    '''\n",
    "    \n",
    "        \n",
    "    ## check data balance: use KFold for balanced data, use StratifiedKFold for imbalanced data\n",
    "    if check_balance(df_train, target): \n",
    "        kf = KFold(n_splits = cv) \n",
    "    else:\n",
    "        kf = StratifiedKFold(n_splits= cv)\n",
    "\n",
    "    X = df_train.drop(columns = [target])\n",
    "    y = df_train[target]\n",
    "    \n",
    "    if feature_groups == None:\n",
    "        feature_groups = X.columns\n",
    "        \n",
    "        \n",
    "    result = []\n",
    "    \n",
    "\n",
    "    for train_index , test_index in kf.split(X, y):\n",
    "        df_train_ = df_train.iloc[train_index]\n",
    "        df_test_ = df_train.iloc[test_index]\n",
    "        \n",
    "\n",
    "        if upsample_flag:\n",
    "            df_train_ = upsample(df_train_, \n",
    "                                target, \n",
    "                                Flag = upsample_flag_show, \n",
    "                                ratio = ratio, \n",
    "                                random_state = random_state, \n",
    "                                replace = replace)\n",
    "\n",
    "        df_x = df_train_.drop(columns = [target])\n",
    "        df_y = df_train_[target]\n",
    "        \n",
    "        df_xtest = df_test_.drop(columns = [target])\n",
    "        df_ytest = df_test_[target]\n",
    "\n",
    "        for clf_name in model_dic:\n",
    "            clf = model_dic[clf_name]\n",
    "            feature_list, estimator_name = Fibe(clf_name, \n",
    "                                                clf, \n",
    "                                                df_x, \n",
    "                                                df_y, \n",
    "                                                score_metric,\n",
    "                                                feature_groups, \n",
    "                                                fibe_cv,\n",
    "                                                fibe_flag_show,\n",
    "                                                Threshold)\n",
    "\n",
    "            \n",
    "            estimator = model_dic[clf_name]\n",
    "            estimator.fit( df_x[feature_list], df_y)\n",
    "            y_predict = estimator.predict( df_xtest[feature_list] ) \n",
    "            \n",
    "            if score_metric == 'accuracy':\n",
    "                current_score = accuracy_score(df_ytest, y_predict)\n",
    "            elif score_metric == 'f1':\n",
    "                current_score = f1_score(df_ytest, y_predict, pos_label = 1)\n",
    "            elif score_metric == 'balanced_accuracy':\n",
    "                current_score = balanced_accuracy_score(df_ytest, y_predict)\n",
    "                \n",
    "            result.append( (clf_name, feature_list, current_score))\n",
    "      \n",
    "\n",
    "\n",
    "    return result\n",
    "\n",
    "def plot(feature_map):\n",
    "    '''\n",
    "    Plot the feature_map information\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_map: a dataframe with each cell is a precentage time that has been choosen\n",
    "    ----------\n",
    "    \n",
    "    return Nothing but a plot\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10)) \n",
    "    ax=plt.subplot()\n",
    "    ax.set_xlabel('features');ax.set_ylabel('Classifier'); \n",
    "    #ax.tick_params(axis='both', which='minor', labelsize=2)\n",
    "\n",
    "    #print (s_outcome)\n",
    "    ax.yaxis.set_ticklabels(feature_map.index,fontsize=10)\n",
    "    ax.xaxis.set_ticklabels(feature_map.columns,rotation=90,fontsize=10)\n",
    "\n",
    "    img=ax.matshow(feature_map,cmap=\"coolwarm\")\n",
    "    plt.colorbar(img, ax=ax,location=\"bottom\")\n",
    "    ax.yaxis.set_major_locator(IndexLocator(base=1,offset=0.5))  # <- HERE\n",
    "    ax.xaxis.set_major_locator(IndexLocator(base=1,offset=0.5))  # <- HERE\n",
    "\n",
    "    plt.savefig(\"FEATURE_SELECTION.png\", \n",
    "                   bbox_inches='tight', \n",
    "\n",
    "                   pad_inches=0) \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def grab_info(result, df, target , cv =5 , threshold = 0.7):\n",
    "    \n",
    "    '''\n",
    "    Grab the FIBE information \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    result: result from model selection\n",
    "    df: dataframe used for columns selections\n",
    "    target: target of the task\n",
    "    cv: number of cross_validation it makes\n",
    "    threshold: set a threshold to get the most common features\n",
    "    \n",
    "    ----------\n",
    "    \n",
    "    return two dictionaries and a selected features: one is the best features based on score, one the most voted features\n",
    "    '''\n",
    "    \n",
    "    dic_best = dict()\n",
    "    dic_vote = dict()\n",
    "    \n",
    "    df = df.drop(columns = [target])\n",
    "    \n",
    "    dd = defaultdict(list)\n",
    "    \n",
    "    for (estimator_name, feature_select, score) in result:\n",
    "        dd[estimator_name].append( (feature_select , score))\n",
    "        \n",
    "    feature_select_df = pd.DataFrame(index=dd.keys(), columns= sorted(df.columns))\n",
    "    feature_select_df = feature_select_df.fillna(0)\n",
    "        \n",
    "    for estimator_name in dd:\n",
    "        l = sorted(dd[estimator_name], key = lambda x: (x[1], -len(x[0])), reverse = True)[0]\n",
    "        #print('the best selection for estimator {} is: {}, '.format(estimator_name, l[0]))\n",
    "        dic_best[estimator_name] = l[0]\n",
    "\n",
    "        for features in dd[estimator_name]:\n",
    "            feature_select_df.loc[estimator_name][features[0]] += 1\n",
    "        \n",
    "    \n",
    "    feature_select_df = feature_select_df.iloc[:,:].apply(lambda x: round(x / cv,2))\n",
    "    \n",
    "    for estimator_name in dd:\n",
    "        A = feature_select_df.loc[estimator_name] >= threshold\n",
    "        select_feature = A[A == True].index.tolist()\n",
    "        #print('the most voted selection for {} , is {}'.format(estimator_name,select_feature))\n",
    "        dic_vote[estimator_name] = select_feature\n",
    "    \n",
    "#     display(feature_select_df)\n",
    "    plot(feature_select_df)\n",
    "    \n",
    "    return dic_best, dic_vote, feature_select_df\n",
    "\n",
    "\n",
    "def magic_selection(df_train, \n",
    "                    df_test, \n",
    "                    score_metric,\n",
    "                    model_dict, \n",
    "                    target,\n",
    "                    cv = 5,\n",
    "                    upsample_flag = False,\n",
    "                    upsample_flag_show = False, \n",
    "                    ratio = 1, \n",
    "                    random_state = 42, \n",
    "                    replace = True ,\n",
    "                    feature_groups = None, \n",
    "                    fibe_cv = 3,\n",
    "                    fibe_flag_show = False,\n",
    "                    Threshold = None,\n",
    "                    threshold_majority = 0.4):\n",
    "    '''\n",
    "    test your feature selection model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_train: training data\n",
    "    \n",
    "    df_test: testing data\n",
    "    \n",
    "    model_dict: a dictionary of model to be used\n",
    "    \n",
    "    target: target value\n",
    "    \n",
    "    cv = 5: default equal to 5 for cross-validation if df_test is None\n",
    "    \n",
    "    upsamle_flag: if True, use upsample method, default False \n",
    "    \n",
    "    upsample_flag_show: if True, show the target distribution, default False\n",
    "    \n",
    "    Ratio: ratio of majority / minority, default is 1\n",
    "    \n",
    "    random_state: for reproducible, default is 42\n",
    "    \n",
    "    replace: sample with replacement or not, default is True\n",
    "    \n",
    "    feature_groups: group features for better explanation. The idea is group one-hot encoder features together.\n",
    "                    default is None\n",
    "    \n",
    "    fibe_cv: cross validation, default = 5\n",
    "    \n",
    "    fibe_flag_show: print detail information, default = False\n",
    "    \n",
    "    threshold: set a threshold for max # number of features you want select, default = False (used in FIBE)\n",
    "    \n",
    "    threshold_majority: set a threshold for #percentage of feature that been voted\n",
    "    \n",
    "    ----------\n",
    "    \n",
    "    return offline metrics for either classification or regression \n",
    "    '''\n",
    "    \n",
    "    if df_test is None:\n",
    "        if check_balance(df_train, target): \n",
    "            kf = KFold(n_splits = cv) \n",
    "        else:\n",
    "            kf = StratifiedKFold(n_splits= cv)\n",
    "            \n",
    "        X = df_train.drop(columns = [target])\n",
    "        y = df_train[target]\n",
    "        \n",
    "        \n",
    "        eval_best = defaultdict(list)\n",
    "        eval_vote = defaultdict(list) \n",
    "            \n",
    "        for train_index , test_index in kf.split(X, y):\n",
    "            df_train_ = df_train.iloc[train_index]\n",
    "            df_test_ = df_train.iloc[test_index]\n",
    "            \n",
    "            data = get_feature_dic(model_dic,\n",
    "                               df_train_, \n",
    "                               target , \n",
    "                               score_metric,\n",
    "                               cv,\n",
    "                               upsample_flag,\n",
    "                               upsample_flag_show, \n",
    "                               ratio, \n",
    "                               random_state, \n",
    "                               replace ,\n",
    "                               feature_groups, \n",
    "                               fibe_cv,\n",
    "                               fibe_flag_show,\n",
    "                               Threshold)\n",
    "        \n",
    "        \n",
    "            dic_best, dic_vote, feature_select_df = grab_info(data, df_train_, target , cv , threshold = threshold_majority)\n",
    "\n",
    "\n",
    "            for estimator_name in model_dict:\n",
    "                estimator = model_dic[estimator_name]\n",
    "\n",
    "                best_feature = dic_best[estimator_name]\n",
    "                vote_feature = dic_vote[estimator_name]\n",
    "\n",
    "                df_x = df_train_.drop(columns = [target])\n",
    "                df_y = df_train_[target]\n",
    "\n",
    "                df_xtest = df_test_.drop(columns = [target])\n",
    "                df_ytest = df_test_[target]\n",
    "                \n",
    "                sensitivity = None\n",
    "                specificity = None\n",
    "\n",
    "                #---------best feature--------#\n",
    "                estimator.fit( df_x[best_feature], df_y)\n",
    "                y_predict = estimator.predict( df_xtest[best_feature])\n",
    "\n",
    "                if score_metric == 'accuracy':\n",
    "                    current_score = accuracy_score(df_ytest, y_predict)\n",
    "                elif score_metric == 'f1':\n",
    "                    current_score = f1_score(df_ytest, y_predict, pos_label = 1)\n",
    "                elif score_metric == 'balanced_accuracy':\n",
    "                    current_score = balanced_accuracy_score(df_ytest, y_predict)\n",
    "                    tn, fp, fn, tp  = confusion_matrix(df_ytest, y_predict).ravel()\n",
    "\n",
    "                    sensitivity = round(tp / (tp + fn),2)\n",
    "                    specificity = round(tn / (tn + fp),2)\n",
    "                                                       \n",
    "                                                       \n",
    "\n",
    "                eval_best[estimator_name].append([current_score,best_feature, sensitivity, specificity])\n",
    "\n",
    "                #--------voted feature--------#\n",
    "                estimator.fit( df_x[vote_feature], df_y)\n",
    "                y_predict = estimator.predict( df_xtest[vote_feature])\n",
    "                \n",
    "                sensitivity = None\n",
    "                specificity = None\n",
    "                \n",
    "                if score_metric == 'accuracy':\n",
    "                    current_score = accuracy_score(df_ytest, y_predict)\n",
    "                elif score_metric == 'f1':\n",
    "                    current_score = f1_score(df_ytest, y_predict, pos_label = 1)\n",
    "                elif score_metric == 'balanced_accuracy':\n",
    "                    current_score = balanced_accuracy_score(df_ytest, y_predict)\n",
    "                    \n",
    "                    tn, fp, fn, tp  = confusion_matrix(df_ytest, y_predict).ravel()\n",
    "\n",
    "                    sensitivity = round(tp / (tp + fn),2)\n",
    "                    specificity = round(tn / (tn + fp),2)\n",
    "\n",
    "                eval_best[estimator_name].append([current_score,best_feature, sensitivity, specificity])\n",
    "    \n",
    "    else:\n",
    "        data = get_feature_dic(model_dic,\n",
    "                               df_train, \n",
    "                               target , \n",
    "                               score_metric,\n",
    "                               cv,\n",
    "                               upsample_flag,\n",
    "                               upsample_flag_show, \n",
    "                               ratio, \n",
    "                               random_state, \n",
    "                               replace ,\n",
    "                               feature_groups, \n",
    "                               fibe_cv,\n",
    "                               fibe_flag_show,\n",
    "                               Threshold)\n",
    "        \n",
    "        \n",
    "        dic_best, dic_vote, feature_select_df = grab_info(data, df_train, target , cv , threshold = threshold_majority)\n",
    "        \n",
    "        eval_best = defaultdict(list)\n",
    "        eval_vote = defaultdict(list) \n",
    "             \n",
    "        \n",
    "        for estimator_name in model_dict:\n",
    "            estimator = model_dic[estimator_name]\n",
    "\n",
    "            best_feature = dic_best[estimator_name]\n",
    "            vote_feature = dic_vote[estimator_name]\n",
    "\n",
    "            df_x = df_train.drop(columns = [target])\n",
    "            df_y = df_train[target]\n",
    "\n",
    "            df_xtest = df_test.drop(columns = [target])\n",
    "            df_ytest = df_test[target]\n",
    "\n",
    "            \n",
    "            #---------best feature--------#\n",
    "            estimator.fit( df_x[best_feature], df_y)\n",
    "            y_predict = estimator.predict( df_xtest[best_feature])\n",
    "            \n",
    "            sensitivity = None\n",
    "            specificity = None\n",
    "            \n",
    "            if score_metric == 'accuracy':\n",
    "                current_score = accuracy_score(df_ytest, y_predict)\n",
    "                tn, fp, fn, tp  = confusion_matrix(df_ytest, y_predict).ravel()\n",
    "\n",
    "                TPR = round(tp / (tp + fn), 2)\n",
    "                TNR = round(tn / (tn + fp), 2)\n",
    "\n",
    "                eval_best[estimator_name].append([current_score, best_feature])\n",
    "                \n",
    "            elif score_metric == 'f1':\n",
    "                current_score = f1_score(df_ytest, y_predict, pos_label = 1)\n",
    "                eval_best[estimator_name].append([current_score, best_feature])\n",
    "                \n",
    "            elif score_metric == 'balanced_accuracy':\n",
    "                current_score = balanced_accuracy_score(df_ytest, y_predict)\n",
    "                tn, fp, fn, tp  = confusion_matrix(df_ytest, y_predict).ravel()\n",
    "\n",
    "                TPR = round(tp / (tp + fn), 2)\n",
    "                TNR = round(tn / (tn + fp), 2)\n",
    "                \n",
    "                \n",
    "                eval_best[estimator_name].append([current_score,best_feature, TPR, TNR])\n",
    "\n",
    "            #--------voted feature--------#\n",
    "            estimator.fit( df_x[vote_feature], df_y)\n",
    "            y_predict = estimator.predict( df_xtest[vote_feature])\n",
    "            \n",
    "            sensitivity = None\n",
    "            specificity = None\n",
    "            \n",
    "            if score_metric == 'accuracy':\n",
    "                current_score = accuracy_score(df_ytest, y_predict)\n",
    "                tn, fp, fn, tp  = confusion_matrix(df_ytest, y_predict).ravel()\n",
    "\n",
    "                TPR = round(tp / (tp + fn), 2)\n",
    "                TNR = round(tn / (tn + fp), 2)\n",
    "\n",
    "                eval_vote[estimator_name].append([current_score, vote_feature])\n",
    "                \n",
    "            elif score_metric == 'f1':\n",
    "                current_score = f1_score(df_ytest, y_predict, pos_label = 1)\n",
    "                eval_vote[estimator_name].append([current_score, vote_feature])\n",
    "            elif score_metric == 'balanced_accuracy':\n",
    "                current_score = balanced_accuracy_score(df_ytest, y_predict)\n",
    "                tn, fp, fn, tp  = confusion_matrix(df_ytest, y_predict).ravel()\n",
    "\n",
    "                TPR = round(tp / (tp + fn), 2)\n",
    "                TNR = round(tn / (tn + fp), 2)\n",
    "                \n",
    "                \n",
    "                eval_vote[estimator_name].append([current_score,vote_feature, TPR, TNR])\n",
    "                \n",
    "       \n",
    "    if score_metric == 'balanced_accuracy':\n",
    "        result_df = pd.DataFrame(columns= ['Model','BSF', 'BSF-TPR','BSF-TNR','MVF', 'MVF-TPR','MVF-TNR'])\n",
    "        for estimator_name in eval_vote:\n",
    "            best_score , best_feature, sensitivity1, specificity1 = max(eval_best[estimator_name], key = lambda x: (x[0], -len(x[1])))\n",
    "            vote_score , vote_feature, sensitivity, specificity  = max(eval_vote[estimator_name], key = lambda x: (x[0], -len(x[1])))\n",
    "\n",
    "            result_df.loc[len(result_df.index)] = [estimator_name, ','.join(best_feature), sensitivity1, specificity1, ','.join(vote_feature), sensitivity, specificity ]\n",
    "\n",
    "    \n",
    "    else:\n",
    "        result_df = pd.DataFrame(columns= ['Model','BSF', 'BSF-Score','MVF','MVF-Score'])\n",
    "        for estimator_name in eval_vote:\n",
    "            best_score , best_feature = max(eval_best[estimator_name], key = lambda x: (x[0], -len(x[1])))\n",
    "            vote_score , vote_feature = max(eval_vote[estimator_name], key = lambda x: (x[0], -len(x[1])))\n",
    "\n",
    "            result_df.loc[len(result_df.index)] = [estimator_name, ','.join(best_feature), best_score, ','.join(vote_feature), vote_score]\n",
    "\n",
    "    return result_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b95311",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outcome = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_groups = []\n",
    "\n",
    "model_dic = {\n",
    "        'Decision Tree': tree.DecisionTreeClassifier(random_state = 11),\n",
    "        'random forest classifer': RandomForestClassifier(random_state = 11),\n",
    "        'AdaBoost classifier': AdaBoostClassifier(random_state = 11),\n",
    "        'SVM linear classifier' : SVC(kernel = 'linear',random_state = 11),\n",
    "        'SVM gaussian classifier' : SVC(random_state = 11)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce686a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show = magic_selection(df_train = , \n",
    "                          df_test = , \n",
    "                          model_dict = model_dic, \n",
    "                          score_metric = 'accuracy',\n",
    "                          target = '',  \n",
    "                          feature_groups = feature_groups,\n",
    "                          upsample_flag = False,\n",
    "                          ratio = 1,\n",
    "                          cv = 5,\n",
    "                          threshold_majority = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cfd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_show)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
